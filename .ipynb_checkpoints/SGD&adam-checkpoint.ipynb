{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "52a4f88a",
   "metadata": {},
   "source": [
    "## MNIST数据集读取"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8f545d57",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "训练集图像格式为: (50000, 784) 训练集标签格式为: (50000,)\n",
      "验证集图像格式为: (10000, 784) 验证集标签格式为: (10000,)\n",
      "测试集图像格式为: (10000, 784) 测试集标签格式为: (10000,)\n"
     ]
    }
   ],
   "source": [
    "import gzip\n",
    "import os\n",
    "import struct\n",
    "import numpy as np\n",
    "\n",
    "def load_mnist(path, kind='train'):\n",
    "    \"\"\"加载MNIST数据集\"\"\"\n",
    "    labels_path = os.path.join(path, f'{kind}-labels-idx1-ubyte.gz')\n",
    "    images_path = os.path.join(path, f'{kind}-images-idx3-ubyte.gz')\n",
    "\n",
    "    with gzip.open(labels_path, 'rb') as lbpath:\n",
    "        struct.unpack('>II', lbpath.read(8))\n",
    "        labels = np.frombuffer(lbpath.read(), dtype=np.uint8)\n",
    "\n",
    "    with gzip.open(images_path, 'rb') as imgpath:\n",
    "        struct.unpack('>IIII', imgpath.read(16))\n",
    "        images = np.frombuffer(imgpath.read(), dtype=np.uint8).reshape(len(labels), 784)\n",
    "\n",
    "    return images, labels\n",
    "\n",
    "\n",
    "\n",
    "# 数据集划分\n",
    "def data_split(images, labels, ratio):\n",
    "    \n",
    "    total_len = images.shape[0]\n",
    "    offset = int(total_len * ratio)\n",
    "    \n",
    "    val_img = images[:offset][:]\n",
    "    val_lb = labels[:offset]\n",
    "    \n",
    "    train_img = images[offset:][:]\n",
    "    train_lb = labels[offset:]\n",
    "    \n",
    "    return train_img, train_lb, val_img, val_lb    \n",
    "\n",
    "# 读取训练集和测试集数据\n",
    "[images, labels] = load_mnist('./MNIST', kind='train')\n",
    "[test_img, test_lb] = load_mnist('./MNIST',kind='test')\n",
    "train_img, train_lb, val_img, val_lb = data_split(images, labels, 1/6)\n",
    "\n",
    "\n",
    "# 打印查看数据集格式\n",
    "print('训练集图像格式为:', train_img.shape, '训练集标签格式为:', train_lb.shape)\n",
    "print('验证集图像格式为:', val_img.shape, '验证集标签格式为:', val_lb.shape)\n",
    "print('测试集图像格式为:', test_img.shape, '测试集标签格式为:', test_lb.shape)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "8acf03d4",
   "metadata": {},
   "source": [
    "## 用SGD+Momentum+CrossEntropyLoss来训练 Linear Classifier"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "b4b5a244",
   "metadata": {},
   "source": [
    "### 定义Cross Entropy Loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c6633e76",
   "metadata": {},
   "outputs": [],
   "source": [
    "def vectorized_loss_softmax(X, y, W):\n",
    "    \"\"\"\n",
    "    Inputs have dimension D=784, there are C=10 classes, and we operate on N=50000 examples.\n",
    "    \n",
    "    Inputs:\n",
    "    - W: Indexs of linear classifier, a numpy array of shape (D, C) containing weights.\n",
    "    - X: Training images, a numpy array of shape (N, D) containing a minibatch of data.\n",
    "    - y: Training labels, a numpy array of shape (N,) containing training labels; y[i] = c means\n",
    "         that X[i] has label c, where 0 <= c < C.\n",
    "    \n",
    "    Returns a tuple of:\n",
    "    - Softmax loss as single float.\n",
    "    \"\"\"\n",
    "    \n",
    "    # set the value of delta, lamda\n",
    "    delta = 1.0\n",
    "    lamda = 1.0\n",
    "    num_train = X.shape[0]\n",
    "    num_class = W.shape[1]\n",
    "    \n",
    "    # scores: class x examples\n",
    "    scores = W.T.dot(X.T).reshape(num_class, num_train)\n",
    "    \n",
    "    # scores_max: 1 x examples, get the max value from each column\n",
    "    scores_max = np.reshape(np.max(scores, axis=0), (1, num_train))\n",
    "\n",
    "    # prob: class x examples, calculate the log probability\n",
    "    # use scores_max to limit the boundary of exp indexes\n",
    "    prob = np.exp(scores-scores_max) / np.sum(np.exp(scores-scores_max), axis=0)\n",
    "\n",
    "    # set value 1 in true label positions, 0 for false labels\n",
    "    y_true = np.zeros(prob.shape)\n",
    "    y_true[y, np.arange(num_train)] = 1.0\n",
    "    \n",
    "    # calculate the average data loss\n",
    "    loss = -np.sum(y_true * np.log(prob))/num_train\n",
    "    \n",
    "    # add L1 regularization loss\n",
    "    rw = np.sum(np.abs(W))\n",
    "    loss += lamda * rw\n",
    "    \n",
    "    return loss"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "6c7551a0",
   "metadata": {},
   "source": [
    "### 定义梯度计算函数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "39e7e018",
   "metadata": {},
   "outputs": [],
   "source": [
    "# compute the numeric gradient\n",
    "def compute_gradient(img, lb, X):\n",
    "    \"\"\"\n",
    "    Inputs have dimension D=784, there are C=10 classes, and we operate on N=1000 examples.\n",
    "    \n",
    "    Inputs:\n",
    "    - img: Training images, a numpy array of shape (N, D) containing a minibatch of data.\n",
    "    - lb: Training labels, a numpy array of shape (N,) containing training labels; y[i] = c means\n",
    "          that X[i] has label c, where 0 <= c < C.\n",
    "    - X: Indexs of linear classifier, a numpy array of shape (D, C) containing weights.\n",
    "    \n",
    "    Returns:\n",
    "    - Numeric gradient dx\n",
    "    \"\"\"\n",
    "    \n",
    "    # initalize the gradient matrix dx\n",
    "    dx = np.zeros(X.shape)\n",
    "    h = 0.0001\n",
    "    \n",
    "    # calculate the inital loss fx\n",
    "    fx = vectorized_loss_softmax(img, lb, X)\n",
    "    \n",
    "    # iterate the each value\n",
    "    for c in range(X.shape[1]):\n",
    "        for d in range(X.shape[0]):\n",
    "            # evaluate function(x+h)\n",
    "            org_val = X[d][c]\n",
    "\n",
    "            # increment by h\n",
    "            X[d][c] = org_val + h\n",
    "\n",
    "            # evalute the softmax loss for f(x+h)\n",
    "            fxh = vectorized_loss_softmax(img, lb, X)\n",
    "\n",
    "            # restore to previous value\n",
    "            X[d][c] = org_val\n",
    "\n",
    "            # compute the partial derivative\n",
    "            dx[d][c] = (fxh - fx) / h\n",
    "\n",
    "    return dx\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "7a78692b",
   "metadata": {},
   "source": [
    "### 定义SGD+Momentum优化器"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ec0932db",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# SGD training function\n",
    "def Train_with_SGD(img, lb, epoch):\n",
    "    \"\"\"\n",
    "    Inputs have dimension D=784, there are C=10 classes, and we operate on N=1000 examples.\n",
    "    \n",
    "    Inputs:\n",
    "    - img: Training images, a numpy array of shape (N, D) containing a minibatch of data.\n",
    "    - lb: Training labels, a numpy array of shape (N,) containing training labels; y[i] = c means\n",
    "          that X[i] has label c, where 0 <= c < C.\n",
    "    - epoch: Training iterations, an integer.\n",
    "    \n",
    "    Returns:\n",
    "    - Best indexs X\n",
    "    \"\"\"\n",
    "    \n",
    "    # set the hyperparameters\n",
    "    beta1 = 0.9\n",
    "    beta2 = 0.999\n",
    "    learning_rate = 5e-4\n",
    "    first_momentum = 0\n",
    "    second_momentum = 0\n",
    "    \n",
    "    # initialize the indexs X\n",
    "    X = np.random.randn(img.shape[1], 10) * 0.0001\n",
    "    \n",
    "    # start training\n",
    "    for i in range(1, epoch + 1):\n",
    "        # compute the gradient\n",
    "        dx = compute_gradient(img, lb,X)\n",
    "        \n",
    "        # momentum\n",
    "        first_momentum = beta1 * first_momentum + (1-beta1) * dx\n",
    "        \n",
    "        # update the indexs X\n",
    "        X -= learning_rate * first_momentum \n",
    "        \n",
    "        # calculate the loss and accuracy\n",
    "        loss = vectorized_loss_softmax(img,lb , X)\n",
    "        scores =  X.T.dot(img.T)\n",
    "        y_pred = np.argmax(scores, axis=0)\n",
    "        accuracy = np.mean(y_pred == lb) * 100\n",
    "        \n",
    "        # print the result\n",
    "        print(\"Epoch: %d  Loss: %.3f  Acc: %.3f%%\" % (i, loss, accuracy))\n",
    "    \n",
    "    return X"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "496a39e5",
   "metadata": {},
   "source": [
    "### 在训练集上进行训练"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "bab40dd9",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1  Loss: 2.253  Acc: 69.200%\n",
      "Epoch: 2  Loss: 5.642  Acc: 52.600%\n",
      "Epoch: 3  Loss: 7.472  Acc: 48.400%\n",
      "Epoch: 4  Loss: 9.727  Acc: 61.700%\n",
      "Epoch: 5  Loss: 9.298  Acc: 64.100%\n",
      "Epoch: 6  Loss: 5.525  Acc: 79.100%\n",
      "Epoch: 7  Loss: 9.381  Acc: 56.400%\n",
      "Epoch: 8  Loss: 8.295  Acc: 68.400%\n",
      "Epoch: 9  Loss: 9.557  Acc: 68.600%\n",
      "Epoch: 10  Loss: 9.152  Acc: 73.800%\n",
      "Epoch: 11  Loss: 8.152  Acc: 76.000%\n",
      "Epoch: 12  Loss: 7.492  Acc: 80.200%\n",
      "Epoch: 13  Loss: 7.969  Acc: 76.000%\n",
      "Epoch: 14  Loss: 7.806  Acc: 80.500%\n",
      "Epoch: 15  Loss: 7.453  Acc: 78.400%\n",
      "Epoch: 16  Loss: 6.755  Acc: 85.200%\n",
      "Epoch: 17  Loss: 6.798  Acc: 85.300%\n",
      "Epoch: 18  Loss: 6.690  Acc: 83.400%\n",
      "Epoch: 19  Loss: 6.572  Acc: 82.400%\n",
      "Epoch: 20  Loss: 5.865  Acc: 85.800%\n",
      "Epoch: 21  Loss: 5.237  Acc: 90.200%\n",
      "Epoch: 22  Loss: 5.471  Acc: 85.700%\n",
      "Epoch: 23  Loss: 5.501  Acc: 82.700%\n",
      "Epoch: 24  Loss: 4.943  Acc: 83.500%\n",
      "Epoch: 25  Loss: 4.818  Acc: 85.000%\n",
      "Epoch: 26  Loss: 4.530  Acc: 82.700%\n",
      "Epoch: 27  Loss: 5.268  Acc: 68.400%\n",
      "Epoch: 28  Loss: 5.843  Acc: 77.800%\n",
      "Epoch: 29  Loss: 6.744  Acc: 71.300%\n",
      "Epoch: 30  Loss: 6.140  Acc: 63.000%\n",
      "Epoch: 31  Loss: 6.111  Acc: 69.200%\n",
      "Epoch: 32  Loss: 6.004  Acc: 69.300%\n",
      "Epoch: 33  Loss: 5.063  Acc: 80.200%\n",
      "Epoch: 34  Loss: 6.184  Acc: 71.700%\n",
      "Epoch: 35  Loss: 5.983  Acc: 69.600%\n",
      "Epoch: 36  Loss: 5.019  Acc: 75.200%\n",
      "Epoch: 37  Loss: 7.264  Acc: 60.100%\n",
      "Epoch: 38  Loss: 5.308  Acc: 81.500%\n",
      "Epoch: 39  Loss: 6.655  Acc: 77.200%\n",
      "Epoch: 40  Loss: 6.634  Acc: 70.200%\n",
      "Epoch: 41  Loss: 4.821  Acc: 84.300%\n",
      "Epoch: 42  Loss: 5.671  Acc: 74.200%\n",
      "Epoch: 43  Loss: 5.660  Acc: 74.400%\n",
      "Epoch: 44  Loss: 4.984  Acc: 83.400%\n",
      "Epoch: 45  Loss: 5.249  Acc: 81.000%\n",
      "Epoch: 46  Loss: 4.869  Acc: 82.300%\n",
      "Epoch: 47  Loss: 4.251  Acc: 83.400%\n",
      "Epoch: 48  Loss: 4.704  Acc: 77.000%\n",
      "Epoch: 49  Loss: 3.988  Acc: 79.700%\n",
      "Epoch: 50  Loss: 3.746  Acc: 80.400%\n",
      "Epoch: 51  Loss: 4.286  Acc: 72.600%\n",
      "Epoch: 52  Loss: 3.453  Acc: 80.200%\n",
      "Epoch: 53  Loss: 4.551  Acc: 65.300%\n",
      "Epoch: 54  Loss: 6.087  Acc: 71.100%\n",
      "Epoch: 55  Loss: 6.945  Acc: 65.400%\n",
      "Epoch: 56  Loss: 5.148  Acc: 67.200%\n",
      "Epoch: 57  Loss: 8.632  Acc: 43.000%\n",
      "Epoch: 58  Loss: 7.740  Acc: 58.700%\n",
      "Epoch: 59  Loss: 10.625  Acc: 50.600%\n",
      "Epoch: 60  Loss: 10.979  Acc: 54.500%\n",
      "Epoch: 61  Loss: 9.639  Acc: 65.000%\n",
      "Epoch: 62  Loss: 10.027  Acc: 59.500%\n",
      "Epoch: 63  Loss: 8.179  Acc: 73.200%\n",
      "Epoch: 64  Loss: 8.716  Acc: 75.100%\n",
      "Epoch: 65  Loss: 9.089  Acc: 75.900%\n",
      "Epoch: 66  Loss: 8.506  Acc: 79.700%\n",
      "Epoch: 67  Loss: 8.148  Acc: 82.900%\n",
      "Epoch: 68  Loss: 7.892  Acc: 84.600%\n",
      "Epoch: 69  Loss: 8.191  Acc: 83.000%\n",
      "Epoch: 70  Loss: 7.928  Acc: 80.900%\n",
      "Epoch: 71  Loss: 7.244  Acc: 84.500%\n",
      "Epoch: 72  Loss: 6.918  Acc: 87.400%\n",
      "Epoch: 73  Loss: 6.858  Acc: 85.100%\n",
      "Epoch: 74  Loss: 6.567  Acc: 86.900%\n",
      "Epoch: 75  Loss: 6.246  Acc: 85.700%\n",
      "Epoch: 76  Loss: 5.874  Acc: 88.200%\n",
      "Epoch: 77  Loss: 5.545  Acc: 87.300%\n",
      "Epoch: 78  Loss: 5.261  Acc: 85.000%\n",
      "Epoch: 79  Loss: 4.979  Acc: 85.700%\n",
      "Epoch: 80  Loss: 4.711  Acc: 88.100%\n",
      "Epoch: 81  Loss: 4.500  Acc: 85.600%\n",
      "Epoch: 82  Loss: 4.534  Acc: 78.500%\n",
      "Epoch: 83  Loss: 5.488  Acc: 75.500%\n",
      "Epoch: 84  Loss: 6.473  Acc: 73.400%\n",
      "Epoch: 85  Loss: 5.274  Acc: 71.400%\n",
      "Epoch: 86  Loss: 6.850  Acc: 51.000%\n",
      "Epoch: 87  Loss: 8.421  Acc: 54.300%\n",
      "Epoch: 88  Loss: 9.150  Acc: 62.400%\n",
      "Epoch: 89  Loss: 10.116  Acc: 53.200%\n",
      "Epoch: 90  Loss: 8.057  Acc: 59.800%\n",
      "Epoch: 91  Loss: 6.366  Acc: 73.500%\n",
      "Epoch: 92  Loss: 9.632  Acc: 57.400%\n",
      "Epoch: 93  Loss: 9.513  Acc: 59.300%\n",
      "Epoch: 94  Loss: 7.808  Acc: 76.700%\n",
      "Epoch: 95  Loss: 8.598  Acc: 75.100%\n",
      "Epoch: 96  Loss: 9.443  Acc: 72.800%\n",
      "Epoch: 97  Loss: 8.693  Acc: 76.400%\n",
      "Epoch: 98  Loss: 8.789  Acc: 77.200%\n",
      "Epoch: 99  Loss: 7.807  Acc: 82.700%\n",
      "Epoch: 100  Loss: 7.660  Acc: 80.900%\n"
     ]
    }
   ],
   "source": [
    "# train the linear classifier with adam in 1000 examples\n",
    "epoch = 100\n",
    "best_X = Train_with_SGD(train_img[0:1000], train_lb[0:1000], epoch)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "3e11efc6",
   "metadata": {},
   "source": [
    "### 在验证集上测试分类效果"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3cfb9030",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SGD_Momentum优化器在验证集上的分类精度为: 74.400%\n"
     ]
    }
   ],
   "source": [
    "# test the classification accuracy on validation dataset\n",
    "\n",
    "# scores: class x examples\n",
    "scores =  best_X.T.dot(val_img.T)\n",
    "\n",
    "# get the predicted labels\n",
    "# y_pred: examples\n",
    "y_pred = np.argmax(scores, axis=0)\n",
    "\n",
    "# calculate the accuracy\n",
    "accuracy = np.mean(y_pred == val_lb) * 100\n",
    "\n",
    "# print the accuracy\n",
    "print(\"SGD_Momentum优化器在验证集上的分类精度为: %.3f%%\" % accuracy)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "991023bb",
   "metadata": {},
   "source": [
    "## 使用Adam优化器进行训练"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "66a44e15",
   "metadata": {},
   "source": [
    "### 定义Adam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "acd0371c",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Adam training function\n",
    "def Train_with_Adam(img, lb, epoch):\n",
    "    \"\"\"\n",
    "    Inputs have dimension D=784, there are C=10 classes, and we operate on N=1000 examples.\n",
    "    \n",
    "    Inputs:\n",
    "    - img: Training images, a numpy array of shape (N, D) containing a minibatch of data.\n",
    "    - lb: Training labels, a numpy array of shape (N,) containing training labels; y[i] = c means\n",
    "          that X[i] has label c, where 0 <= c < C.\n",
    "    - epoch: Training iterations, an integer.\n",
    "    \n",
    "    Returns:\n",
    "    - Best indexs X\n",
    "    \"\"\"\n",
    "    \n",
    "    # set the hyperparameters\n",
    "    beta1 = 0.9\n",
    "    beta2 = 0.999\n",
    "    learning_rate = 5e-4\n",
    "    first_momentum = 0\n",
    "    second_momentum = 0\n",
    "    \n",
    "    # initialize the indexs X\n",
    "    X = np.random.randn(img.shape[1], 10) * 0.0001\n",
    "    \n",
    "    # start training\n",
    "    for i in range(1, epoch + 1):\n",
    "        # compute the gradient\n",
    "        dx = compute_gradient(img, lb, X)\n",
    "        \n",
    "        # momentum\n",
    "        first_momentum = beta1* first_momentum + (1-beta1)*dx\n",
    "        # adagrad\n",
    "        second_momentum = beta2*second_momentum +(1-beta2)*dx*dx\n",
    "        \n",
    "        # bias correction\n",
    "        first_unbias = first_momentum /(1-beta1**i)\n",
    "        second_unbias = second_momentum/(1-beta2**i)\n",
    "        \n",
    "        # update the indexs X\n",
    "        X = -learning_rate * first_unbias / (np.sqrt(second_unbias)+1e-7)\n",
    "        \n",
    "        # calculate the loss and accuracy\n",
    "        loss = vectorized_loss_softmax(img, lb, X)\n",
    "        scores =  X.T.dot(img.T)\n",
    "        y_pred = np.argmax(scores, axis=0)\n",
    "        accuracy = np.mean(y_pred == lb) * 100\n",
    "        \n",
    "        # print the result\n",
    "        print(\"Epoch: %d  Loss: %.3f  Acc: %.3f%%\" % (i, loss, accuracy))\n",
    "    \n",
    "    return X"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "bf551c4f",
   "metadata": {},
   "source": [
    "### 在训练集上进行训练"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ed6f7745",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1  Loss: 6.370  Acc: 51.700%\n",
      "Epoch: 2  Loss: 6.639  Acc: 45.000%\n",
      "Epoch: 3  Loss: 5.909  Acc: 38.300%\n",
      "Epoch: 4  Loss: 4.369  Acc: 33.600%\n",
      "Epoch: 5  Loss: 2.989  Acc: 47.500%\n",
      "Epoch: 6  Loss: 2.421  Acc: 51.200%\n",
      "Epoch: 7  Loss: 1.910  Acc: 63.900%\n",
      "Epoch: 8  Loss: 1.736  Acc: 66.500%\n",
      "Epoch: 9  Loss: 1.754  Acc: 71.000%\n",
      "Epoch: 10  Loss: 1.551  Acc: 77.700%\n",
      "Epoch: 11  Loss: 1.625  Acc: 77.100%\n",
      "Epoch: 12  Loss: 1.546  Acc: 79.100%\n",
      "Epoch: 13  Loss: 1.595  Acc: 79.900%\n",
      "Epoch: 14  Loss: 1.552  Acc: 78.900%\n",
      "Epoch: 15  Loss: 1.594  Acc: 79.900%\n",
      "Epoch: 16  Loss: 1.559  Acc: 78.300%\n",
      "Epoch: 17  Loss: 1.598  Acc: 79.200%\n",
      "Epoch: 18  Loss: 1.551  Acc: 79.400%\n",
      "Epoch: 19  Loss: 1.575  Acc: 80.600%\n",
      "Epoch: 20  Loss: 1.542  Acc: 80.100%\n",
      "Epoch: 21  Loss: 1.558  Acc: 82.100%\n",
      "Epoch: 22  Loss: 1.539  Acc: 80.300%\n",
      "Epoch: 23  Loss: 1.552  Acc: 82.200%\n",
      "Epoch: 24  Loss: 1.543  Acc: 79.600%\n",
      "Epoch: 25  Loss: 1.561  Acc: 82.300%\n",
      "Epoch: 26  Loss: 1.563  Acc: 77.900%\n",
      "Epoch: 27  Loss: 1.584  Acc: 79.900%\n",
      "Epoch: 28  Loss: 1.597  Acc: 75.500%\n",
      "Epoch: 29  Loss: 1.586  Acc: 79.700%\n",
      "Epoch: 30  Loss: 1.587  Acc: 75.500%\n",
      "Epoch: 31  Loss: 1.576  Acc: 80.000%\n",
      "Epoch: 32  Loss: 1.575  Acc: 76.000%\n",
      "Epoch: 33  Loss: 1.576  Acc: 80.400%\n",
      "Epoch: 34  Loss: 1.577  Acc: 74.600%\n",
      "Epoch: 35  Loss: 1.583  Acc: 79.200%\n",
      "Epoch: 36  Loss: 1.586  Acc: 73.200%\n",
      "Epoch: 37  Loss: 1.596  Acc: 78.400%\n",
      "Epoch: 38  Loss: 1.600  Acc: 72.100%\n",
      "Epoch: 39  Loss: 1.615  Acc: 77.400%\n",
      "Epoch: 40  Loss: 1.613  Acc: 70.100%\n",
      "Epoch: 41  Loss: 1.639  Acc: 76.400%\n",
      "Epoch: 42  Loss: 1.613  Acc: 69.400%\n",
      "Epoch: 43  Loss: 1.660  Acc: 75.800%\n",
      "Epoch: 44  Loss: 1.591  Acc: 69.200%\n",
      "Epoch: 45  Loss: 1.685  Acc: 75.700%\n",
      "Epoch: 46  Loss: 1.582  Acc: 69.300%\n",
      "Epoch: 47  Loss: 1.688  Acc: 76.100%\n",
      "Epoch: 48  Loss: 1.569  Acc: 69.400%\n",
      "Epoch: 49  Loss: 1.691  Acc: 76.300%\n",
      "Epoch: 50  Loss: 1.568  Acc: 69.300%\n",
      "Epoch: 51  Loss: 1.686  Acc: 76.300%\n",
      "Epoch: 52  Loss: 1.572  Acc: 69.400%\n",
      "Epoch: 53  Loss: 1.681  Acc: 76.100%\n",
      "Epoch: 54  Loss: 1.583  Acc: 68.900%\n",
      "Epoch: 55  Loss: 1.674  Acc: 75.900%\n",
      "Epoch: 56  Loss: 1.595  Acc: 68.900%\n",
      "Epoch: 57  Loss: 1.663  Acc: 75.700%\n",
      "Epoch: 58  Loss: 1.606  Acc: 68.800%\n",
      "Epoch: 59  Loss: 1.656  Acc: 75.800%\n",
      "Epoch: 60  Loss: 1.615  Acc: 68.700%\n",
      "Epoch: 61  Loss: 1.650  Acc: 75.900%\n",
      "Epoch: 62  Loss: 1.622  Acc: 68.500%\n",
      "Epoch: 63  Loss: 1.647  Acc: 75.700%\n",
      "Epoch: 64  Loss: 1.626  Acc: 68.400%\n",
      "Epoch: 65  Loss: 1.646  Acc: 75.900%\n",
      "Epoch: 66  Loss: 1.630  Acc: 68.400%\n",
      "Epoch: 67  Loss: 1.645  Acc: 75.900%\n",
      "Epoch: 68  Loss: 1.632  Acc: 68.400%\n",
      "Epoch: 69  Loss: 1.646  Acc: 75.900%\n",
      "Epoch: 70  Loss: 1.633  Acc: 68.200%\n",
      "Epoch: 71  Loss: 1.647  Acc: 75.900%\n",
      "Epoch: 72  Loss: 1.633  Acc: 68.200%\n",
      "Epoch: 73  Loss: 1.649  Acc: 75.700%\n",
      "Epoch: 74  Loss: 1.633  Acc: 68.200%\n",
      "Epoch: 75  Loss: 1.651  Acc: 75.600%\n",
      "Epoch: 76  Loss: 1.631  Acc: 68.200%\n",
      "Epoch: 77  Loss: 1.654  Acc: 75.500%\n",
      "Epoch: 78  Loss: 1.629  Acc: 68.200%\n",
      "Epoch: 79  Loss: 1.659  Acc: 75.500%\n",
      "Epoch: 80  Loss: 1.625  Acc: 68.200%\n",
      "Epoch: 81  Loss: 1.664  Acc: 75.400%\n",
      "Epoch: 82  Loss: 1.619  Acc: 68.100%\n",
      "Epoch: 83  Loss: 1.672  Acc: 75.500%\n",
      "Epoch: 84  Loss: 1.611  Acc: 68.100%\n",
      "Epoch: 85  Loss: 1.681  Acc: 75.400%\n",
      "Epoch: 86  Loss: 1.602  Acc: 68.000%\n",
      "Epoch: 87  Loss: 1.691  Acc: 75.400%\n",
      "Epoch: 88  Loss: 1.592  Acc: 67.800%\n",
      "Epoch: 89  Loss: 1.700  Acc: 75.300%\n",
      "Epoch: 90  Loss: 1.586  Acc: 67.800%\n",
      "Epoch: 91  Loss: 1.704  Acc: 75.300%\n",
      "Epoch: 92  Loss: 1.584  Acc: 67.800%\n",
      "Epoch: 93  Loss: 1.704  Acc: 75.300%\n",
      "Epoch: 94  Loss: 1.587  Acc: 67.800%\n",
      "Epoch: 95  Loss: 1.699  Acc: 75.300%\n",
      "Epoch: 96  Loss: 1.594  Acc: 67.800%\n",
      "Epoch: 97  Loss: 1.691  Acc: 75.200%\n",
      "Epoch: 98  Loss: 1.604  Acc: 67.800%\n",
      "Epoch: 99  Loss: 1.682  Acc: 75.200%\n",
      "Epoch: 100  Loss: 1.613  Acc: 67.700%\n"
     ]
    }
   ],
   "source": [
    "# train the linear classifier with adam in 1000 examples\n",
    "epoch = 100\n",
    "best_X = Train_with_Adam(train_img[0:1000], train_lb[0:1000], epoch)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "3dd745f7",
   "metadata": {},
   "source": [
    "### 在验证集上测试分类效果"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "3de76cdc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SGD_Momentum优化器在验证集上的分类精度为: 62.890%\n"
     ]
    }
   ],
   "source": [
    "# test the classification accuracy on validation dataset\n",
    "\n",
    "# scores: class x examples\n",
    "scores =  best_X.T.dot(val_img.T)\n",
    "\n",
    "# get the predicted labels\n",
    "# y_pred: examples\n",
    "y_pred = np.argmax(scores, axis=0)\n",
    "\n",
    "# calculate the accuracy\n",
    "accuracy = np.mean(y_pred == val_lb) * 100\n",
    "\n",
    "# print the accuracy\n",
    "print(\"SGD_Momentum优化器在验证集上的分类精度为: %.3f%%\" % accuracy)"
   ]
  },
  {
   "cell_type": "raw",
   "id": "3682d87f-5dc6-403e-be37-51720b649845",
   "metadata": {},
   "source": [
    "两种方法均可以求得较小的loss\n",
    "\n",
    "\n",
    "SGD:\n",
    "Epoch: 100  Loss: 7.660  Acc: 80.900%\n",
    "SGD_Momentum优化器在验证集上的分类精度为: 74.400%\n",
    "\n",
    "\n",
    "Adam:\n",
    "Epoch: 100  Loss: 1.613  Acc: 67.700%\n",
    "Adam优化器在验证集上的分类精度为: 62.890%\n",
    "\n",
    "\n",
    "\n",
    "adam的loss取得的更低的值但是精准度不高\n",
    "\n",
    "个人认为有以下几种可能：\n",
    "1loss的计算中没有加入正则化项，有可能出现过拟合\n",
    "2单个层的线性分类器无法解决这个问题\n",
    "\n",
    "同时存在一些问题\n",
    "1计算梯度时的时间复杂度太高\n",
    "可以采用反向梯度传播进行梯度计算\n",
    "\n",
    "2loss这里使用的是均方误差，可以更换为交叉熵损失"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
