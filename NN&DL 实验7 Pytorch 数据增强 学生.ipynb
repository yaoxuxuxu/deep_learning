{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 读取数据"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "训练集图像格式为: (50000, 28, 28) 训练集标签格式为: (50000,) 热编码训练集标签格式为: (50000, 10)\n",
      "验证集图像格式为: (10000, 28, 28) 验证集标签格式为: (10000,) 热编码验证集标签格式为: (10000, 10)\n",
      "测试集图像格式为: (10000, 28, 28) 测试集标签格式为: (10000,) 热编码测试集标签格式为: (10000, 10)\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import datasets\n",
    "from torchvision.transforms import ToTensor\n",
    "import gzip\n",
    "import os\n",
    "import struct\n",
    "import numpy as np\n",
    "\n",
    "def load_mnist(path, kind='train'):\n",
    "    \"\"\"加载MNIST数据集\"\"\"\n",
    "    labels_path = os.path.join(path, f'{kind}-labels-idx1-ubyte.gz')\n",
    "    images_path = os.path.join(path, f'{kind}-images-idx3-ubyte.gz')\n",
    "\n",
    "    with gzip.open(labels_path, 'rb') as lbpath:\n",
    "        struct.unpack('>II', lbpath.read(8))\n",
    "        labels = np.frombuffer(lbpath.read(), dtype=np.uint8)\n",
    "\n",
    "    with gzip.open(images_path, 'rb') as imgpath:\n",
    "        struct.unpack('>IIII', imgpath.read(16))\n",
    "        images = np.frombuffer(imgpath.read(), dtype=np.uint8).reshape(len(labels),28,28)\n",
    "\n",
    "    return images, labels\n",
    "\n",
    "\n",
    "\n",
    "# 数据集划分\n",
    "def data_split(images, labels, ratio):\n",
    "    \n",
    "    total_len = images.shape[0]\n",
    "    offset = int(total_len * ratio)\n",
    "\n",
    "    val_img = images[:offset][:]\n",
    "    val_lb = labels[:offset]\n",
    "\n",
    "    train_img = images[offset:][:]\n",
    "    train_lb = labels[offset:]\n",
    "\n",
    "    return train_img, train_lb, val_img, val_lb    \n",
    "\n",
    "# 读取训练集和测试集数据\n",
    "[images, labels] = load_mnist('./MNIST', kind='train')\n",
    "[test_img, test_lb] = load_mnist('./MNIST',kind='test')\n",
    "train_img, train_lb, val_img, val_lb = data_split(images, labels, 1/6)\n",
    "\n",
    "# 为了加快调试速度，从训练集选择2000个样本。\n",
    "#train_img=train_img[0:2000]\n",
    "\n",
    "# 将所有数据归一化到0-1之间\n",
    "train_img =train_img/255.\n",
    "val_img   =val_img/255.\n",
    "test_img  =test_img/255.\n",
    "\n",
    "# 对标签进行热编码\n",
    "one_hot_train_lb = np.eye(10)[train_lb]\n",
    "one_hot_val_lb = np.eye(10)[val_lb]\n",
    "one_hot_test_lb= np.eye(10)[test_lb]\n",
    "\n",
    "# 打印查看数据集格式\n",
    "print('训练集图像格式为:', train_img.shape, '训练集标签格式为:', train_lb.shape,'热编码训练集标签格式为:', one_hot_train_lb.shape)\n",
    "print('验证集图像格式为:', val_img.shape, '验证集标签格式为:', val_lb.shape,'热编码验证集标签格式为:', one_hot_val_lb.shape)\n",
    "print('测试集图像格式为:', test_img.shape, '测试集标签格式为:', test_lb.shape,'热编码测试集标签格式为:', one_hot_test_lb.shape)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 数据增强处理"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([100000, 28, 28])\n",
      "(100000, 10)\n"
     ]
    }
   ],
   "source": [
    "# 程序改错\n",
    "from torchvision.transforms import v2\n",
    "transforms = v2.Compose([\n",
    "    v2.RandomHorizontalFlip(),\n",
    "    #v2.RandomVerticalFlip(),\n",
    "    v2.Normalize(mean=[0.406],std=[0.225]),\n",
    "    v2.RandomRotation(degrees=(-45, 45))\n",
    "    ])\n",
    "train_img=torch.tensor(train_img,dtype=torch.float)\n",
    "augmented_sample = transforms(train_img)\n",
    "# 将增强后的数据添加到训练集中\n",
    "train_img = torch.cat((augmented_sample,train_img),dim=0)\n",
    "one_hot_train_lb=np.concatenate((one_hot_train_lb,one_hot_train_lb),axis=0)\n",
    "print(train_img.shape)\n",
    "print(one_hot_train_lb.shape)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 使用增强处理后的数据，训练网络"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_436743/2987195528.py:46: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  X=torch.tensor(X)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Epoch:0, loss: 0.271465,  Accuracy: 92.0%\n",
      " Epoch:1, loss: 0.135024,  Accuracy: 96.3%\n",
      " Epoch:2, loss: 0.090018,  Accuracy: 97.3%\n",
      " Epoch:3, loss: 0.063365,  Accuracy: 98.0%\n",
      " Epoch:4, loss: 0.048150,  Accuracy: 98.5%\n",
      " Epoch:5, loss: 0.042705,  Accuracy: 98.6%\n",
      " Epoch:6, loss: 0.035888,  Accuracy: 98.8%\n",
      " Epoch:7, loss: 0.032163,  Accuracy: 99.0%\n",
      " Epoch:8, loss: 0.029450,  Accuracy: 99.0%\n",
      " Epoch:9, loss: 0.029315,  Accuracy: 99.1%\n",
      " Epoch:10, loss: 0.020865,  Accuracy: 99.3%\n",
      " Epoch:11, loss: 0.024634,  Accuracy: 99.2%\n",
      " Epoch:12, loss: 0.018106,  Accuracy: 99.4%\n",
      " Epoch:13, loss: 0.019715,  Accuracy: 99.4%\n",
      " Epoch:14, loss: 0.018186,  Accuracy: 99.4%\n",
      " Epoch:15, loss: 0.015403,  Accuracy: 99.5%\n",
      " Epoch:16, loss: 0.016620,  Accuracy: 99.5%\n",
      " Epoch:17, loss: 0.017757,  Accuracy: 99.5%\n",
      " Epoch:18, loss: 0.017566,  Accuracy: 99.5%\n",
      " Epoch:19, loss: 0.013412,  Accuracy: 99.6%\n",
      " Epoch:20, loss: 0.010552,  Accuracy: 99.6%\n",
      " Epoch:21, loss: 0.015626,  Accuracy: 99.5%\n",
      " Epoch:22, loss: 0.014650,  Accuracy: 99.6%\n",
      " Epoch:23, loss: 0.010560,  Accuracy: 99.7%\n",
      " Epoch:24, loss: 0.017226,  Accuracy: 99.5%\n",
      " Epoch:25, loss: 0.009909,  Accuracy: 99.7%\n",
      " Epoch:26, loss: 0.011960,  Accuracy: 99.7%\n",
      " Epoch:27, loss: 0.015066,  Accuracy: 99.6%\n",
      " Epoch:28, loss: 0.012643,  Accuracy: 99.6%\n",
      " Epoch:29, loss: 0.009148,  Accuracy: 99.7%\n",
      " Epoch:30, loss: 0.007355,  Accuracy: 99.8%\n",
      " Epoch:31, loss: 0.008980,  Accuracy: 99.7%\n",
      " Epoch:32, loss: 0.014105,  Accuracy: 99.6%\n",
      " Epoch:33, loss: 0.010874,  Accuracy: 99.7%\n",
      " Epoch:34, loss: 0.007500,  Accuracy: 99.8%\n",
      " Epoch:35, loss: 0.009588,  Accuracy: 99.7%\n",
      " Epoch:36, loss: 0.008197,  Accuracy: 99.8%\n",
      " Epoch:37, loss: 0.014751,  Accuracy: 99.6%\n",
      " Epoch:38, loss: 0.009421,  Accuracy: 99.8%\n",
      " Epoch:39, loss: 0.005969,  Accuracy: 99.8%\n",
      " Epoch:40, loss: 0.014010,  Accuracy: 99.6%\n",
      " Epoch:41, loss: 0.009374,  Accuracy: 99.8%\n",
      " Epoch:42, loss: 0.008544,  Accuracy: 99.8%\n",
      " Epoch:43, loss: 0.005640,  Accuracy: 99.9%\n",
      " Epoch:44, loss: 0.012328,  Accuracy: 99.7%\n",
      " Epoch:45, loss: 0.011318,  Accuracy: 99.7%\n",
      " Epoch:46, loss: 0.005929,  Accuracy: 99.9%\n",
      " Epoch:47, loss: 0.008409,  Accuracy: 99.8%\n",
      " Epoch:48, loss: 0.010065,  Accuracy: 99.8%\n",
      " Epoch:49, loss: 0.009996,  Accuracy: 99.7%\n",
      " Epoch:50, loss: 0.009873,  Accuracy: 99.8%\n",
      " Epoch:51, loss: 0.011729,  Accuracy: 99.7%\n",
      " Epoch:52, loss: 0.007772,  Accuracy: 99.8%\n",
      " Epoch:53, loss: 0.011411,  Accuracy: 99.7%\n",
      " Epoch:54, loss: 0.008731,  Accuracy: 99.8%\n",
      " Epoch:55, loss: 0.005527,  Accuracy: 99.9%\n",
      " Epoch:56, loss: 0.004947,  Accuracy: 99.9%\n",
      " Epoch:57, loss: 0.011596,  Accuracy: 99.8%\n",
      " Epoch:58, loss: 0.010480,  Accuracy: 99.8%\n",
      " Epoch:59, loss: 0.004894,  Accuracy: 99.9%\n",
      " Epoch:60, loss: 0.007407,  Accuracy: 99.8%\n",
      " Epoch:61, loss: 0.010355,  Accuracy: 99.8%\n",
      " Epoch:62, loss: 0.007027,  Accuracy: 99.8%\n",
      " Epoch:63, loss: 0.009646,  Accuracy: 99.8%\n",
      " Epoch:64, loss: 0.009432,  Accuracy: 99.8%\n",
      " Epoch:65, loss: 0.009273,  Accuracy: 99.8%\n",
      " Epoch:66, loss: 0.007239,  Accuracy: 99.9%\n",
      " Epoch:67, loss: 0.003033,  Accuracy: 99.9%\n",
      " Epoch:68, loss: 0.007803,  Accuracy: 99.8%\n",
      " Epoch:69, loss: 0.010023,  Accuracy: 99.8%\n",
      " Epoch:70, loss: 0.012835,  Accuracy: 99.8%\n",
      " Epoch:71, loss: 0.009274,  Accuracy: 99.8%\n",
      " Epoch:72, loss: 0.005993,  Accuracy: 99.9%\n",
      " Epoch:73, loss: 0.011263,  Accuracy: 99.8%\n",
      " Epoch:74, loss: 0.007728,  Accuracy: 99.9%\n",
      " Epoch:75, loss: 0.008388,  Accuracy: 99.8%\n",
      " Epoch:76, loss: 0.011213,  Accuracy: 99.8%\n",
      " Epoch:77, loss: 0.006540,  Accuracy: 99.9%\n",
      " Epoch:78, loss: 0.004826,  Accuracy: 99.9%\n",
      " Epoch:79, loss: 0.006953,  Accuracy: 99.9%\n",
      " Epoch:80, loss: 0.011886,  Accuracy: 99.8%\n",
      " Epoch:81, loss: 0.008859,  Accuracy: 99.8%\n",
      " Epoch:82, loss: 0.005925,  Accuracy: 99.9%\n",
      " Epoch:83, loss: 0.010270,  Accuracy: 99.8%\n",
      " Epoch:84, loss: 0.008230,  Accuracy: 99.8%\n",
      " Epoch:85, loss: 0.006551,  Accuracy: 99.9%\n",
      " Epoch:86, loss: 0.007590,  Accuracy: 99.9%\n",
      " Epoch:87, loss: 0.013877,  Accuracy: 99.8%\n",
      " Epoch:88, loss: 0.008281,  Accuracy: 99.9%\n",
      " Epoch:89, loss: 0.006701,  Accuracy: 99.9%\n",
      " Epoch:90, loss: 0.009815,  Accuracy: 99.9%\n",
      " Epoch:91, loss: 0.006204,  Accuracy: 99.9%\n",
      " Epoch:92, loss: 0.006815,  Accuracy: 99.9%\n",
      " Epoch:93, loss: 0.006161,  Accuracy: 99.9%\n",
      " Epoch:94, loss: 0.006464,  Accuracy: 99.9%\n",
      " Epoch:95, loss: 0.010934,  Accuracy: 99.8%\n",
      " Epoch:96, loss: 0.007331,  Accuracy: 99.9%\n",
      " Epoch:97, loss: 0.007289,  Accuracy: 99.9%\n",
      " Epoch:98, loss: 0.006854,  Accuracy: 99.9%\n",
      " Epoch:99, loss: 0.004326,  Accuracy: 99.9%\n"
     ]
    }
   ],
   "source": [
    "# 程序改错\n",
    "\n",
    "class NeuralNetwork(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.w1=nn.Linear(28*28, 512)\n",
    "        self.w2=nn.Linear(512, 512)\n",
    "        self.w3=nn.Linear(512, 10)\n",
    "        self.relu=nn.ReLU()\n",
    "        self.drop=nn.Dropout()\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = x.view(len(x),-1)\n",
    "        x = self.w1 (x)\n",
    "        x = self.relu(x)\n",
    "        self.drop(x)\n",
    "        x = self.w2 (x)\n",
    "        x = self.relu(x)\n",
    "        self.drop(x)\n",
    "        x = self.w3 (x)\n",
    "        return x\n",
    "\n",
    "model = NeuralNetwork()\n",
    "\n",
    "# Initialize the loss function\n",
    "loss_fn = nn.CrossEntropyLoss()\n",
    "\n",
    "learning_rate = 1e-3\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)\n",
    "\n",
    "batch_size = 200\n",
    "epochs = 100\n",
    "batch_num=int(train_img.shape[0]/batch_size)\n",
    "size = len(train_img)\n",
    "\n",
    "model.train()\n",
    "for t in range(epochs):\n",
    "    \n",
    "    correct=0.\n",
    "    train_mean_loss=0.\n",
    "\n",
    "    for batch in range(batch_num):\n",
    "        X=train_img[batch*batch_size:(batch+1)*batch_size,]\n",
    "        y=one_hot_train_lb[batch*batch_size:(batch+1)*batch_size,:]\n",
    "\n",
    "        X=torch.tensor(X)\n",
    "        y=torch.tensor(y)\n",
    "        \n",
    "        # Compute prediction and loss\n",
    "        pred = model(X)\n",
    "        loss = loss_fn(pred, y)\n",
    "\n",
    "        # Backpropagation\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        correct += (pred.argmax(1) == y.argmax(1)).type(torch.float).mean().item()\n",
    "        train_mean_loss+= loss.item()\n",
    "\n",
    "    train_mean_loss /= batch_num\n",
    "    correct /= batch_num\n",
    "    \n",
    "    print(f\" Epoch:{t}, loss: {train_mean_loss:>8f},  Accuracy: {(100*correct):>0.1f}%\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy: 98.4%, Test Avg loss: 0.151334 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "model.eval()\n",
    "test_loss, correct = 0., 0.\n",
    "with torch.no_grad():\n",
    "        X=torch.tensor(test_img, dtype=torch.float32)\n",
    "        y=torch.tensor(one_hot_test_lb, dtype=torch.float32)\n",
    "        pred = model(X)\n",
    "        test_loss = np.mean(loss_fn(pred, y).item())\n",
    "        correct = (pred.argmax(1) == y.argmax(1)).type(torch.float).mean().item()\n",
    "\n",
    "print(f\"Test Accuracy: {(100*correct):>0.1f}%, Test Avg loss: {test_loss:>8f} \\n\")\n"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Test Accuracy: 98.4%, Test Avg loss: 0.151334\n",
    "做了数据增强，同时使用了dropout正则化\n",
    "精确率达到98%+，非常准确。"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
