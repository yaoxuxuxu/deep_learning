{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "实验要求\n",
    "1、读取UC遥感数据\n",
    "2、调整第八次实验课搭建的CNN网络，使其能够用于UC数据分类\n",
    "3、测试CNN网络分类效果\n",
    "4、搭建一个VGG网络（VGG结构见课堂PPT），用于分类UC数据，对比与3层卷积CNN网络的分类性能差异。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 读取UC数据"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "import numpy as np\n",
    "import os\n",
    "import cv2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['agricultural', 'airplane', 'baseballdiamond', 'beach', 'buildings', 'chaparral', 'denseresidential', 'forest', 'freeway']\n",
      "['agricultural', 'airplane', 'baseballdiamond', 'beach', 'buildings', 'chaparral', 'denseresidential', 'forest', 'freeway']\n"
     ]
    }
   ],
   "source": [
    "a=os.listdir('./UCMerced_LandUse/validation/')\n",
    "b=os.listdir('./UCMerced_LandUse/train/')\n",
    "print(a)\n",
    "print(b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(720, 3, 256, 256)\n",
      "(180, 3, 256, 256)\n",
      "训练集图像格式为: (720, 3, 256, 256) 训练集标签格式为: (720, 9) 热编码训练集标签格式为: (720, 9)\n",
      "测试集图像格式为: (180, 3, 256, 256) 测试集标签格式为: (180, 9) 热编码测试集标签格式为: (180, 9)\n"
     ]
    }
   ],
   "source": [
    "def read_UC(path):\n",
    "    # 初始化变量\n",
    "    X = np.zeros((1,3,256,256))\n",
    "    Y = []\n",
    "    # 补充 #\n",
    "    lbcnt=0\n",
    "    for fp in os.listdir(path):\n",
    "        for j in os.listdir(path+fp):\n",
    "            tmp=cv2.imread(path+fp+\"/\"+j)\n",
    "            tmp=cv2.resize(tmp,(256,256))\n",
    "            tmp=np.transpose(tmp,(2,0,1))\n",
    "            tmp=np.reshape(tmp,(1,3,256,256))\n",
    "            \n",
    "            X=np.concatenate((X,tmp))\n",
    "            Y.append(lbcnt)\n",
    "        lbcnt+=1\n",
    "    X=X[1:]\n",
    "    X=X.astype(np.float32)\n",
    "    Y=np.array(Y)\n",
    "    return X,Y\n",
    "\n",
    "# 读取训练集和测试集数据\n",
    "[train_img, train_lb] = read_UC('./UCMerced_LandUse/train/')\n",
    "[test_img, test_lb] = read_UC('./UCMerced_LandUse/validation/')\n",
    "print(train_img.shape)\n",
    "print(test_img.shape)\n",
    "\n",
    "# 将所有数据归一化到0-1之间\n",
    "train_img =train_img/255.\n",
    "test_img   =test_img/255.\n",
    "\n",
    "# 对标签进行热编码\n",
    "train_lb = np.eye(9)[train_lb]\n",
    "test_lb = np.eye(9)[test_lb]\n",
    "\n",
    "index = np.random.permutation(train_img.shape[0])\n",
    "train_img = train_img[index]\n",
    "train_lb = train_lb[index]\n",
    "index = np.random.permutation(test_img.shape[0])\n",
    "test_img = test_img[index]\n",
    "test_lb = test_lb[index]\n",
    "\n",
    "# 打印查看数据集格式\n",
    "print('训练集图像格式为:', train_img.shape, '训练集标签格式为:', train_lb.shape,'热编码训练集标签格式为:', train_lb.shape)\n",
    "print('测试集图像格式为:', test_img.shape, '测试集标签格式为:', test_lb.shape,'热编码测试集标签格式为:', test_lb.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0. 0. 1. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 1. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " ...\n",
      " [0. 0. 0. ... 0. 0. 1.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 1. 0.]]\n"
     ]
    }
   ],
   "source": [
    "np.savez(\"dataset\",train_img,train_lb,test_img,test_lb)\n",
    "print(\"saved\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "训练集图像格式为: (720, 3, 256, 256) 训练集标签格式为: (720, 9) 热编码训练集标签格式为: (720, 9)\n",
      "测试集图像格式为: (180, 3, 256, 256) 测试集标签格式为: (180, 9) 热编码测试集标签格式为: (180, 9)\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "import numpy as np\n",
    "import os\n",
    "import cv2\n",
    "tmp=np.load(\"dataset.npz\")\n",
    "train_img=tmp[\"arr_0\"]\n",
    "train_lb=tmp[\"arr_1\"]\n",
    "test_img=tmp[\"arr_2\"]\n",
    "test_lb=tmp[\"arr_3\"]\n",
    "print('训练集图像格式为:', train_img.shape, '训练集标签格式为:', train_lb.shape,'热编码训练集标签格式为:', train_lb.shape)\n",
    "print('测试集图像格式为:', test_img.shape, '测试集标签格式为:', test_lb.shape,'热编码测试集标签格式为:', test_lb.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 数据增强处理"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "训练集图像格式为: torch.Size([1440, 3, 256, 256]) 训练集标签格式为: (1440, 9) 热编码训练集标签格式为: (1440, 9)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "from torchvision.transforms import v2\n",
    "from torchvision.io import read_image\n",
    "train_img1=torch.tensor(train_img, dtype=torch.float32)\n",
    "transforms = v2.Compose([\n",
    "    v2.RandomHorizontalFlip(p=0.5),\n",
    "    #v2.Normalize(mean=[0.485,0.485,0.485], std=[0.229,0.229,0.229]),\n",
    "    v2.RandomRotation(degrees=(0, 180))\n",
    "    ])\n",
    "normal= v2.Compose([v2.Normalize(mean=[0.485,0.485,0.485], std=[0.229,0.229,0.229])])\n",
    "augmented_sample = transforms(train_img1)\n",
    "#train_img1= normal(train_img1)\n",
    "#test_img = normal(test_img)\n",
    "train_img = torch.cat((augmented_sample,train_img1))\n",
    "train_lb  = np.concatenate((train_lb,train_lb),axis=0)\n",
    "\n",
    "print('训练集图像格式为:', train_img.shape, '训练集标签格式为:', train_lb.shape,'热编码训练集标签格式为:', train_lb.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "使用增强处理后的数据，训练网络"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TRAIN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\15432\\AppData\\Local\\Temp\\ipykernel_14416\\2157150321.py:63: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  X=torch.tensor(X, dtype=torch.float32)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Epoch:1, loss: 2.199222,  Accuracy: 12.3%\n",
      " Epoch:2, loss: 2.163816,  Accuracy: 14.9%\n",
      " Epoch:3, loss: 2.126990,  Accuracy: 17.9%\n",
      " Epoch:4, loss: 2.045382,  Accuracy: 22.7%\n",
      " Epoch:5, loss: 1.967567,  Accuracy: 25.5%\n",
      " Epoch:6, loss: 1.878051,  Accuracy: 28.2%\n",
      " Epoch:7, loss: 1.888043,  Accuracy: 28.1%\n",
      " Epoch:8, loss: 1.852163,  Accuracy: 30.6%\n",
      " Epoch:9, loss: 1.835782,  Accuracy: 34.0%\n",
      " Epoch:10, loss: 1.752299,  Accuracy: 34.1%\n",
      " Epoch:11, loss: 1.703156,  Accuracy: 39.4%\n",
      " Epoch:12, loss: 1.681556,  Accuracy: 38.2%\n",
      " Epoch:13, loss: 1.625558,  Accuracy: 41.6%\n",
      " Epoch:14, loss: 1.574025,  Accuracy: 43.2%\n",
      " Epoch:15, loss: 1.668702,  Accuracy: 42.0%\n",
      " Epoch:16, loss: 1.585002,  Accuracy: 42.5%\n",
      " Epoch:17, loss: 1.529841,  Accuracy: 43.7%\n",
      " Epoch:18, loss: 1.489644,  Accuracy: 46.9%\n",
      " Epoch:19, loss: 1.442913,  Accuracy: 48.8%\n",
      " Epoch:20, loss: 1.415444,  Accuracy: 51.8%\n",
      " Epoch:21, loss: 1.373322,  Accuracy: 52.6%\n",
      " Epoch:22, loss: 1.311752,  Accuracy: 55.7%\n",
      " Epoch:23, loss: 1.273688,  Accuracy: 55.6%\n",
      " Epoch:24, loss: 1.258690,  Accuracy: 56.0%\n",
      " Epoch:25, loss: 1.229266,  Accuracy: 57.0%\n",
      " Epoch:26, loss: 1.186509,  Accuracy: 60.0%\n",
      " Epoch:27, loss: 1.152746,  Accuracy: 59.8%\n",
      " Epoch:28, loss: 1.203173,  Accuracy: 59.4%\n",
      " Epoch:29, loss: 1.175084,  Accuracy: 58.3%\n",
      " Epoch:30, loss: 1.103537,  Accuracy: 62.6%\n",
      " Epoch:31, loss: 1.127557,  Accuracy: 61.9%\n",
      " Epoch:32, loss: 1.044070,  Accuracy: 63.5%\n",
      " Epoch:33, loss: 1.068589,  Accuracy: 62.8%\n",
      " Epoch:34, loss: 1.038966,  Accuracy: 64.6%\n",
      " Epoch:35, loss: 1.050524,  Accuracy: 63.5%\n",
      " Epoch:36, loss: 1.016694,  Accuracy: 66.1%\n",
      " Epoch:37, loss: 0.955144,  Accuracy: 67.4%\n",
      " Epoch:38, loss: 0.964147,  Accuracy: 67.9%\n",
      " Epoch:39, loss: 0.965884,  Accuracy: 67.7%\n",
      " Epoch:40, loss: 0.894743,  Accuracy: 69.6%\n",
      " Epoch:41, loss: 0.894024,  Accuracy: 69.4%\n",
      " Epoch:42, loss: 0.923634,  Accuracy: 69.0%\n",
      " Epoch:43, loss: 0.828464,  Accuracy: 72.6%\n",
      " Epoch:44, loss: 0.912415,  Accuracy: 69.5%\n",
      " Epoch:45, loss: 0.849955,  Accuracy: 71.6%\n",
      " Epoch:46, loss: 0.823229,  Accuracy: 72.1%\n",
      " Epoch:47, loss: 0.852706,  Accuracy: 71.7%\n",
      " Epoch:48, loss: 0.799001,  Accuracy: 72.9%\n",
      " Epoch:49, loss: 0.776475,  Accuracy: 74.5%\n",
      " Epoch:50, loss: 0.786235,  Accuracy: 73.7%\n",
      " Epoch:51, loss: 0.762410,  Accuracy: 73.4%\n",
      " Epoch:52, loss: 0.786842,  Accuracy: 73.9%\n",
      " Epoch:53, loss: 0.776883,  Accuracy: 74.1%\n",
      " Epoch:54, loss: 0.770701,  Accuracy: 74.1%\n",
      " Epoch:55, loss: 0.726426,  Accuracy: 74.5%\n",
      " Epoch:56, loss: 0.680447,  Accuracy: 77.8%\n",
      " Epoch:57, loss: 0.679750,  Accuracy: 77.2%\n",
      " Epoch:58, loss: 0.670758,  Accuracy: 78.6%\n",
      " Epoch:59, loss: 0.647076,  Accuracy: 80.6%\n",
      " Epoch:60, loss: 0.711908,  Accuracy: 77.6%\n",
      " Epoch:61, loss: 0.621251,  Accuracy: 81.6%\n",
      " Epoch:62, loss: 0.480664,  Accuracy: 87.5%\n",
      " Epoch:63, loss: 0.527009,  Accuracy: 84.2%\n",
      " Epoch:64, loss: 0.797119,  Accuracy: 73.6%\n",
      " Epoch:65, loss: 0.570133,  Accuracy: 82.4%\n",
      " Epoch:66, loss: 0.519356,  Accuracy: 85.1%\n",
      " Epoch:67, loss: 0.530600,  Accuracy: 83.1%\n",
      " Epoch:68, loss: 0.492904,  Accuracy: 84.4%\n",
      " Epoch:69, loss: 0.450225,  Accuracy: 86.9%\n",
      " Epoch:70, loss: 0.706925,  Accuracy: 77.1%\n",
      " Epoch:71, loss: 0.479651,  Accuracy: 84.5%\n",
      " Epoch:72, loss: 0.406166,  Accuracy: 88.9%\n",
      " Epoch:73, loss: 0.501287,  Accuracy: 85.3%\n",
      " Epoch:74, loss: 0.401564,  Accuracy: 88.4%\n",
      " Epoch:75, loss: 0.409870,  Accuracy: 87.4%\n",
      " Epoch:76, loss: 0.842075,  Accuracy: 73.4%\n",
      " Epoch:77, loss: 0.493039,  Accuracy: 84.5%\n",
      " Epoch:78, loss: 0.434864,  Accuracy: 86.6%\n",
      " Epoch:79, loss: 0.404861,  Accuracy: 87.9%\n",
      " Epoch:80, loss: 0.474655,  Accuracy: 84.6%\n",
      " Epoch:81, loss: 0.396835,  Accuracy: 87.9%\n",
      " Epoch:82, loss: 0.362672,  Accuracy: 89.6%\n",
      " Epoch:83, loss: 0.347454,  Accuracy: 89.0%\n",
      " Epoch:84, loss: 0.336947,  Accuracy: 90.4%\n",
      " Epoch:85, loss: 0.326565,  Accuracy: 90.7%\n",
      " Epoch:86, loss: 0.367592,  Accuracy: 88.3%\n",
      " Epoch:87, loss: 0.410344,  Accuracy: 86.2%\n",
      " Epoch:88, loss: 0.283194,  Accuracy: 91.6%\n",
      " Epoch:89, loss: 0.289644,  Accuracy: 92.4%\n",
      " Epoch:90, loss: 0.284204,  Accuracy: 92.0%\n",
      " Epoch:91, loss: 0.277287,  Accuracy: 91.9%\n",
      " Epoch:92, loss: 0.309604,  Accuracy: 90.1%\n",
      " Epoch:93, loss: 0.369631,  Accuracy: 88.7%\n",
      " Epoch:94, loss: 0.257604,  Accuracy: 93.3%\n",
      " Epoch:95, loss: 0.259854,  Accuracy: 92.2%\n",
      " Epoch:96, loss: 0.335885,  Accuracy: 91.1%\n",
      " Epoch:97, loss: 0.293104,  Accuracy: 91.5%\n",
      " Epoch:98, loss: 0.348484,  Accuracy: 89.1%\n",
      " Epoch:99, loss: 0.245253,  Accuracy: 93.3%\n",
      " Epoch:100, loss: 0.282482,  Accuracy: 91.6%\n"
     ]
    }
   ],
   "source": [
    "class NeuralNetwork(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.conv1=nn.Conv2d(in_channels=3,out_channels=10, kernel_size=16,stride=2)\n",
    "        self.conv2=nn.Conv2d(in_channels=10,out_channels=20,kernel_size=15,stride=2)\n",
    "        self.conv3=nn.Conv2d(in_channels=20,out_channels=10,kernel_size=10,stride=2)\n",
    "        self.w1 =nn.Linear(23*23*10,100)\n",
    "        self.w2 =nn.Linear(100,9)\n",
    "        self.BN1=nn.BatchNorm2d(10)\n",
    "        self.BN2=nn.BatchNorm2d(20)\n",
    "        self.BN3=nn.BatchNorm2d(10)\n",
    "        self.relu=nn.ReLU()\n",
    "        self.drop=nn.Dropout(p=0.5)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.conv1 (x)\n",
    "        x = self.BN1(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.conv2 (x)\n",
    "        x = self.BN2(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.conv3(x)\n",
    "        x = self.BN3(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.drop(x)\n",
    "        x = x.view(x.size(0), -1)\n",
    "        x = self.w1 (x)\n",
    "        x = self.relu(x)\n",
    "        x = self.drop(x)\n",
    "        x = self.w2 (x)\n",
    "        x = self.relu(x)\n",
    "        \n",
    "        return x\n",
    "\n",
    "# Initialize the loss function\n",
    "gpu=1\n",
    "model = NeuralNetwork()\n",
    "loss_fn = nn.CrossEntropyLoss()\n",
    "learning_rate = 5e-3\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=learning_rate)\n",
    "\n",
    "if gpu:\n",
    "    if torch.cuda.is_available():\n",
    "        model= model.cuda()\n",
    "        loss_fn=loss_fn.cuda()\n",
    "    else:\n",
    "        gpu=0\n",
    "\n",
    "batch_size = 200\n",
    "epochs = 100\n",
    "batch_num=int(train_img.shape[0]/batch_size)\n",
    "size = len(train_img)\n",
    "\n",
    "model.train()\n",
    "for t in range(epochs):\n",
    "    \n",
    "    correct=0.\n",
    "    train_mean_loss=0.\n",
    "\n",
    "    for batch in range(batch_num):\n",
    "        X=train_img[batch*batch_size:(batch+1)*batch_size,]\n",
    "        y=train_lb[batch*batch_size:(batch+1)*batch_size,:]\n",
    "        X=torch.tensor(X, dtype=torch.float32)\n",
    "        y=torch.tensor(y, dtype=torch.float32)\n",
    "        if gpu:\n",
    "            X=X.cuda()\n",
    "            y=y.cuda()\n",
    "        # Compute prediction and loss\n",
    "        pred = model(X)\n",
    "        loss = loss_fn(pred, y)\n",
    "\n",
    "        # Backpropagation\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        correct += (pred.argmax(1) == y.argmax(1)).type(torch.float).mean().item()\n",
    "        train_mean_loss+= loss.item()\n",
    "\n",
    "    train_mean_loss /= batch_num\n",
    "    correct /= batch_num\n",
    "    \n",
    "    print(f\" Epoch:{t+1}, loss: {train_mean_loss:>8f},  Accuracy: {(100*correct):>0.1f}%\")\n",
    "    if (t+1)%10==0:\n",
    "        torch.save(model,str(t+1)+\".pt\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## EVAL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy: 57.2%, Test Avg loss: 1.723464 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "class NeuralNetwork(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.conv1=nn.Conv2d(in_channels=3,out_channels=10, kernel_size=16,stride=2)\n",
    "        self.conv2=nn.Conv2d(in_channels=10,out_channels=20,kernel_size=15,stride=2)\n",
    "        self.conv3=nn.Conv2d(in_channels=20,out_channels=10,kernel_size=10,stride=2)\n",
    "        self.w1 =nn.Linear(23*23*10,100)\n",
    "        self.w2 =nn.Linear(100,9)\n",
    "        self.BN1=nn.BatchNorm2d(10)\n",
    "        self.BN2=nn.BatchNorm2d(20)\n",
    "        self.BN3=nn.BatchNorm2d(10)\n",
    "        self.relu=nn.ReLU()\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.conv1 (x)\n",
    "        x = self.BN1(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.conv2 (x)\n",
    "        x = self.BN2(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.conv3 (x)\n",
    "        x = self.BN3(x)\n",
    "        x = self.relu(x)\n",
    "        x = x.view(x.size(0), -1)\n",
    "        x = self.w1 (x)\n",
    "        x = self.relu(x)\n",
    "        x = self.w2 (x)\n",
    "        x = self.relu(x)        \n",
    "        return x\n",
    "model=NeuralNetwork()\n",
    "model=torch.load(\"100.pt\")\n",
    "gpu=0\n",
    "if torch.cuda.is_available():\n",
    "    gpu=1\n",
    "    model=model.cuda()\n",
    "model.eval()\n",
    "test_loss, correct = 0, 0\n",
    "with torch.no_grad():\n",
    "    X=torch.tensor(test_img, dtype=torch.float32)\n",
    "    y=torch.tensor(test_lb, dtype=torch.float32)\n",
    "    if gpu:\n",
    "        X=X.cuda()\n",
    "        y=y.cuda()\n",
    "    pred = model(X)\n",
    "    test_loss = np.mean(loss_fn(pred, y).item())\n",
    "    correct = (pred.argmax(1) == y.argmax(1)).type(torch.float).mean().item()\n",
    "\n",
    "print(f\"Test Accuracy: {(100*correct):>0.1f}%, Test Avg loss: {test_loss:>8f} \\n\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## VGGNet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "load success\n",
      "train from epoch 20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\15432\\AppData\\Local\\Temp\\ipykernel_1800\\2253354472.py:141: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  X = torch.tensor(X, dtype=torch.float32)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Epoch:21, loss: 0.500593,  Accuracy: 85.2%\n",
      " Epoch:22, loss: 0.307095,  Accuracy: 90.3%\n",
      " Epoch:23, loss: 0.182059,  Accuracy: 93.8%\n",
      " Epoch:24, loss: 0.116370,  Accuracy: 95.9%\n",
      " Epoch:25, loss: 0.127077,  Accuracy: 96.1%\n",
      " Epoch:26, loss: 0.117656,  Accuracy: 95.7%\n",
      " Epoch:27, loss: 0.166254,  Accuracy: 93.9%\n",
      " Epoch:28, loss: 0.130747,  Accuracy: 95.5%\n",
      " Epoch:29, loss: 0.108476,  Accuracy: 96.6%\n",
      " Epoch:30, loss: 0.149163,  Accuracy: 94.8%\n",
      "saving\n",
      "save complete\n",
      " Epoch:31, loss: 0.129268,  Accuracy: 96.1%\n",
      " Epoch:32, loss: 0.060697,  Accuracy: 98.2%\n",
      " Epoch:33, loss: 0.025975,  Accuracy: 99.4%\n",
      " Epoch:34, loss: 0.020746,  Accuracy: 99.1%\n",
      " Epoch:35, loss: 0.036502,  Accuracy: 98.9%\n",
      " Epoch:36, loss: 0.022289,  Accuracy: 99.1%\n",
      " Epoch:37, loss: 0.049174,  Accuracy: 98.6%\n",
      " Epoch:38, loss: 0.055279,  Accuracy: 98.2%\n",
      " Epoch:39, loss: 0.082887,  Accuracy: 97.2%\n",
      " Epoch:40, loss: 0.055619,  Accuracy: 98.6%\n",
      "saving\n",
      "save complete\n",
      " Epoch:41, loss: 0.012355,  Accuracy: 99.7%\n",
      " Epoch:42, loss: 0.032001,  Accuracy: 98.9%\n",
      " Epoch:43, loss: 0.020751,  Accuracy: 99.5%\n",
      " Epoch:44, loss: 0.017425,  Accuracy: 99.4%\n",
      " Epoch:45, loss: 0.014083,  Accuracy: 99.6%\n",
      " Epoch:46, loss: 0.029796,  Accuracy: 99.3%\n",
      " Epoch:47, loss: 0.021411,  Accuracy: 99.4%\n",
      " Epoch:48, loss: 0.030923,  Accuracy: 99.3%\n",
      " Epoch:49, loss: 0.031607,  Accuracy: 98.9%\n",
      " Epoch:50, loss: 0.053713,  Accuracy: 98.8%\n",
      "saving\n",
      "save complete\n",
      " Epoch:51, loss: 0.057975,  Accuracy: 98.0%\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "import numpy as np\n",
    "import os\n",
    "from torchvision.transforms import v2\n",
    "\n",
    "batch_size = 64\n",
    "epochs = 50\n",
    "gpu=1\n",
    "\n",
    "\n",
    "def continue_to_train():\n",
    "    maxx=-1\n",
    "    for i in os.listdir(\"./\"):\n",
    "        if \".pt\" in i and \"vggnet\" in i:\n",
    "            tmp=i.replace(\"vggnet\",\"\")\n",
    "            tmp=tmp.replace(\".pt\",\"\")\n",
    "            tmp=int(tmp)\n",
    "            maxx=max(tmp,maxx)\n",
    "    return maxx\n",
    "def autofit_lr(t):\n",
    "    if t<99:\n",
    "        return 0.1-(1e-3)*t\n",
    "    return 1e-3\n",
    "\n",
    "tmp=np.load(\"dataset.npz\")\n",
    "train_img=tmp[\"arr_0\"]\n",
    "train_lb=tmp[\"arr_1\"]\n",
    "test_img=tmp[\"arr_2\"]\n",
    "test_lb=tmp[\"arr_3\"]\n",
    "\n",
    "train_img1=torch.tensor(train_img, dtype=torch.float32)\n",
    "\n",
    "transforms = v2.Compose([\n",
    "    v2.RandomHorizontalFlip(p=0.5),\n",
    "    #v2.Normalize(mean=[0.485,0.485,0.485], std=[0.229,0.229,0.229]),\n",
    "    v2.RandomRotation(degrees=(0, 180))\n",
    "    ])\n",
    "#normal= v2.Compose([v2.Normalize(mean=[0.485,0.485,0.485], std=[0.229,0.229,0.229])])\n",
    "augmented_sample = transforms(train_img1)\n",
    "#test_img = normal(test_img)\n",
    "#train_img1=normal(train_img1)\n",
    "train_img = torch.cat((augmented_sample,train_img1))\n",
    "train_lb  = np.concatenate((train_lb,train_lb),axis=0)\n",
    "\n",
    "\n",
    "\n",
    "class NeuralNetwork(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.conv1 = nn.Sequential(nn.Conv2d(in_channels=3, out_channels=64, kernel_size=3, stride=1, padding=1),\n",
    "                                   nn.ReLU(True),\n",
    "                                   nn.Conv2d(in_channels=64, out_channels=64, kernel_size=3, stride=1, padding=1),\n",
    "                                   nn.ReLU(True),\n",
    "                                   nn.MaxPool2d(2, stride=2))\n",
    "        self.conv2 = nn.Sequential(nn.Conv2d(in_channels=64, out_channels=128, kernel_size=3, stride=1, padding=1),\n",
    "                                   nn.ReLU(True),\n",
    "                                   nn.Conv2d(in_channels=128, out_channels=128, kernel_size=3, stride=1, padding=1),\n",
    "                                   nn.ReLU(True),\n",
    "                                   nn.MaxPool2d(2, stride=2))\n",
    "        self.conv3 = nn.Sequential(nn.Conv2d(in_channels=128, out_channels=256, kernel_size=3, stride=1, padding=1),\n",
    "                                   nn.ReLU(True),\n",
    "                                   nn.Conv2d(in_channels=256, out_channels=256, kernel_size=3, stride=1, padding=1),\n",
    "                                   nn.ReLU(True),\n",
    "                                   nn.MaxPool2d(2, stride=2))\n",
    "        self.conv4 = nn.Sequential(nn.Conv2d(in_channels=256, out_channels=512, kernel_size=3, stride=1, padding=1),\n",
    "                                   nn.ReLU(True),\n",
    "                                   nn.Conv2d(in_channels=512, out_channels=512, kernel_size=3, stride=1, padding=1),\n",
    "                                   nn.ReLU(True),\n",
    "                                   nn.Conv2d(in_channels=512, out_channels=512, kernel_size=3, stride=1, padding=1),\n",
    "                                   nn.ReLU(True),\n",
    "                                   nn.MaxPool2d(2, stride=2))\n",
    "        self.conv5 = nn.Sequential(nn.Conv2d(in_channels=512, out_channels=512, kernel_size=3, stride=1, padding=1),\n",
    "                                   nn.ReLU(True),\n",
    "                                   nn.Conv2d(in_channels=512, out_channels=512, kernel_size=3, stride=1, padding=1),\n",
    "                                   nn.ReLU(True),\n",
    "                                   nn.Conv2d(in_channels=512, out_channels=512, kernel_size=3, stride=1, padding=1),\n",
    "                                   nn.ReLU(True),\n",
    "                                   nn.MaxPool2d(2, stride=2))\n",
    "        self.lin = nn.Sequential(nn.Linear(32768, 4096),\n",
    "                                 nn.ReLU(True),\n",
    "                                 nn.Dropout(p=0.5),\n",
    "                                 nn.Linear(4096, 4096),\n",
    "                                 nn.ReLU(True),\n",
    "                                 nn.Dropout(p=0.5),\n",
    "                                 nn.Linear(4096, 9))\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.conv1(x)\n",
    "        x = self.conv2(x)\n",
    "        x = self.conv3(x)\n",
    "        x = self.conv4(x)\n",
    "        x = self.conv5(x)\n",
    "        x = x.view(x.size(0), -1)\n",
    "        x = self.lin(x)\n",
    "        return x\n",
    "    def init(self):\n",
    "        for m in self.modules():\n",
    "            if isinstance(m, nn.Conv2d):\n",
    "                torch.nn.init.xavier_uniform_(m.weight)\n",
    "            if isinstance(m, nn.Linear):\n",
    "                torch.nn.init.xavier_uniform_(m.weight)\n",
    "# Initialize the loss function\n",
    "model = NeuralNetwork()\n",
    "tmp=continue_to_train()\n",
    "t=0\n",
    "if tmp != -1:\n",
    "    model=torch.load(\"vggnet\"+str(tmp)+\".pt\")\n",
    "    print(\"load success\")\n",
    "    print(\"train from epoch \"+str(tmp))\n",
    "    t=tmp\n",
    "else:\n",
    "    model.init()\n",
    "loss_fn = nn.CrossEntropyLoss()\n",
    "learning_rate = 1e-4\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate,weight_decay=5e-4)\n",
    "\n",
    "if gpu:\n",
    "    if not torch.cuda.is_available():\n",
    "        gpu = 0\n",
    "\n",
    "if gpu:\n",
    "    model = model.cuda()\n",
    "    loss_fn = loss_fn.cuda()\n",
    "\n",
    "\n",
    "batch_num = int(train_img.shape[0] / batch_size)\n",
    "size = len(train_img)\n",
    "\n",
    "model.train()\n",
    "while 1:\n",
    "    if t>epochs:\n",
    "        break\n",
    "\n",
    "    correct = 0.\n",
    "    train_mean_loss = 0.\n",
    "\n",
    "    for batch in range(batch_num):\n",
    "        X = train_img[batch * batch_size:(batch + 1) * batch_size, ]\n",
    "        y = train_lb[batch * batch_size:(batch + 1) * batch_size, :]\n",
    "        X = torch.tensor(X, dtype=torch.float32)\n",
    "        y = torch.tensor(y, dtype=torch.float32)\n",
    "        if gpu:\n",
    "            X = X.cuda()\n",
    "            y = y.cuda()\n",
    "        # Compute prediction and loss\n",
    "        pred = model(X)\n",
    "        loss = loss_fn(pred, y)\n",
    "\n",
    "        # Backpropagation\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        correct += (pred.argmax(1) == y.argmax(1)).type(torch.float).mean().item()\n",
    "        train_mean_loss += loss.item()\n",
    "\n",
    "    train_mean_loss /= batch_num\n",
    "    correct /= batch_num\n",
    "\n",
    "    print(f\" Epoch:{t + 1}, loss: {train_mean_loss:>8f},  Accuracy: {(100 * correct):>0.1f}%\")\n",
    "    if (t + 1) % 10 == 0:\n",
    "        print(\"saving\")\n",
    "        torch.save(model, \"vggnet\"+str(t + 1) + \".pt\")\n",
    "        print(\"save complete\")\n",
    "    t+=1\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## EVAL VGGNET"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy: 81.1%, Test Avg loss: 1.168858 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "import numpy as np\n",
    "import os\n",
    "from torchvision.transforms import v2\n",
    "\n",
    "batch_size = 100\n",
    "epochs = 10000\n",
    "gpu=1\n",
    "\n",
    "\n",
    "def continue_to_train():\n",
    "    maxx=-1\n",
    "    for i in os.listdir(\"./\"):\n",
    "        if \".pt\" in i:\n",
    "            tmp=i.replace(\"vggnet\",\"\")\n",
    "            tmp=tmp.replace(\".pt\",\"\")\n",
    "            tmp=int(tmp)\n",
    "            maxx=max(tmp,maxx)\n",
    "    return maxx\n",
    "def autofit_lr(t):\n",
    "    if t<99:\n",
    "        return 0.1-(1e-3)*t\n",
    "    return 1e-3\n",
    "\n",
    "tmp=np.load(\"dataset.npz\")\n",
    "train_img=tmp[\"arr_0\"]\n",
    "train_lb=tmp[\"arr_1\"]\n",
    "test_img=tmp[\"arr_2\"]\n",
    "test_lb=tmp[\"arr_3\"]\n",
    "\n",
    "\n",
    "\n",
    "class NeuralNetwork(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.conv1 = nn.Sequential(nn.Conv2d(in_channels=3, out_channels=64, kernel_size=3, stride=1, padding=1),\n",
    "                                   nn.ReLU(),\n",
    "                                   nn.Conv2d(in_channels=64, out_channels=64, kernel_size=3, stride=1, padding=1),\n",
    "                                   nn.ReLU(),\n",
    "                                   nn.MaxPool2d(2, stride=2))\n",
    "        self.conv2 = nn.Sequential(nn.Conv2d(in_channels=64, out_channels=128, kernel_size=3, stride=1, padding=1),\n",
    "                                   nn.ReLU(),\n",
    "                                   nn.Conv2d(in_channels=128, out_channels=128, kernel_size=3, stride=1, padding=1),\n",
    "                                   nn.ReLU(),\n",
    "                                   nn.MaxPool2d(2, stride=2))\n",
    "        self.conv3 = nn.Sequential(nn.Conv2d(in_channels=128, out_channels=256, kernel_size=3, stride=1, padding=1),\n",
    "                                   nn.ReLU(),\n",
    "                                   nn.Conv2d(in_channels=256, out_channels=256, kernel_size=3, stride=1, padding=1),\n",
    "                                   nn.ReLU(),\n",
    "                                   nn.MaxPool2d(2, stride=2))\n",
    "        self.conv4 = nn.Sequential(nn.Conv2d(in_channels=256, out_channels=512, kernel_size=3, stride=1, padding=1),\n",
    "                                   nn.ReLU(),\n",
    "                                   nn.Conv2d(in_channels=512, out_channels=512, kernel_size=3, stride=1, padding=1),\n",
    "                                   nn.ReLU(),\n",
    "                                   nn.Conv2d(in_channels=512, out_channels=512, kernel_size=3, stride=1, padding=1),\n",
    "                                   nn.ReLU(),\n",
    "                                   nn.MaxPool2d(2, stride=2))\n",
    "        self.conv5 = nn.Sequential(nn.Conv2d(in_channels=512, out_channels=512, kernel_size=3, stride=1, padding=1),\n",
    "                                   nn.ReLU(),\n",
    "                                   nn.Conv2d(in_channels=512, out_channels=512, kernel_size=3, stride=1, padding=1),\n",
    "                                   nn.ReLU(),\n",
    "                                   nn.Conv2d(in_channels=512, out_channels=512, kernel_size=3, stride=1, padding=1),\n",
    "                                   nn.ReLU(),\n",
    "                                   nn.MaxPool2d(2, stride=2))\n",
    "        self.lin = nn.Sequential(nn.Linear(32768, 4096),\n",
    "                                 nn.ReLU(),\n",
    "                                 nn.Dropout(p=0.5),\n",
    "                                 nn.Linear(4096, 4096),\n",
    "                                 nn.ReLU(),\n",
    "                                 nn.Dropout(p=0.5),\n",
    "                                 nn.Linear(4096, 9))\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.conv1(x)\n",
    "        x = self.conv2(x)\n",
    "        x = self.conv3(x)\n",
    "        x = self.conv4(x)\n",
    "        x = self.conv5(x)\n",
    "        x = x.view(x.size(0), -1)\n",
    "        x = self.lin(x)\n",
    "        return x\n",
    "\n",
    "\n",
    "model = NeuralNetwork()\n",
    "loss_fn = nn.CrossEntropyLoss()\n",
    "model = torch.load(\"./vggnet40.pt\")\n",
    "gpu = 1\n",
    "if gpu:\n",
    "    if torch.cuda.is_available():\n",
    "        model = model.cuda()\n",
    "        loss_fn = loss_fn.cuda()\n",
    "    else:\n",
    "        gpu = 0\n",
    "model.eval()\n",
    "test_loss, correct = 0, 0\n",
    "size=len(test_img)\n",
    "#size=720\n",
    "for i in range(size):\n",
    "    with torch.no_grad():\n",
    "        X = torch.tensor(test_img[i].reshape(1,3,256,256), dtype=torch.float32)\n",
    "        y = torch.tensor(test_lb[i].reshape(1,9), dtype=torch.float32)\n",
    "        if gpu:\n",
    "            X = X.cuda()\n",
    "            y = y.cuda()\n",
    "        pred = model(X)\n",
    "        test_loss += np.mean(loss_fn(pred, y).item())\n",
    "        correct += (pred.argmax(1) == y.argmax(1)).type(torch.float).mean().item()\n",
    "correct/=size\n",
    "test_loss/=size\n",
    "\n",
    "print(f\"Test Accuracy: {(100 * correct):>0.1f}%, Test Avg loss: {test_loss:>8f} \\n\")\n"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Epoch:100, loss: 0.225048,  Accuracy: 93.3%\n",
    "Test Accuracy: 11.7%, Test Avg loss: 6.563433\n",
    "\n",
    "VGGNET\n",
    "Epoch:51, loss: 0.001477,  Accuracy: 100.0%\n",
    "Test Accuracy: 22.2%, Test Avg loss: 14.823861\n",
    "\n",
    "两者均不能达到一个很好的效果。在训练集上都能达到较高的准确率\n",
    "但是在测试集上并不能达到好的效果，。\n",
    "可能是数据集难度太高，或者也可能是网络过深 Relu激活函数导致梯度消失\n",
    "使得前面的层很难更新权值。而且出现了过拟合现象"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
