{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "52a4f88a",
   "metadata": {},
   "source": [
    "## MNIST数据集读取"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8f545d57",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "训练集图像格式为: (50000, 784) 训练集标签格式为: (50000,)\n",
      "验证集图像格式为: (10000, 784) 验证集标签格式为: (10000,)\n",
      "测试集图像格式为: (10000, 784) 测试集标签格式为: (10000,)\n"
     ]
    }
   ],
   "source": [
    "import gzip\n",
    "import os\n",
    "import struct\n",
    "import numpy as np\n",
    "\n",
    "def load_mnist(path, kind='train'):\n",
    "    \"\"\"加载MNIST数据集\"\"\"\n",
    "    labels_path = os.path.join(path, f'{kind}-labels-idx1-ubyte.gz')\n",
    "    images_path = os.path.join(path, f'{kind}-images-idx3-ubyte.gz')\n",
    "\n",
    "    with gzip.open(labels_path, 'rb') as lbpath:\n",
    "        struct.unpack('>II', lbpath.read(8))\n",
    "        labels = np.frombuffer(lbpath.read(), dtype=np.uint8)\n",
    "\n",
    "    with gzip.open(images_path, 'rb') as imgpath:\n",
    "        struct.unpack('>IIII', imgpath.read(16))\n",
    "        images = np.frombuffer(imgpath.read(), dtype=np.uint8).reshape(len(labels), 784)\n",
    "\n",
    "    return images, labels\n",
    "\n",
    "\n",
    "\n",
    "# 数据集划分\n",
    "def data_split(images, labels, ratio):\n",
    "    \n",
    "    total_len = images.shape[0]\n",
    "    offset = int(total_len * ratio)\n",
    "    \n",
    "    val_img = images[:offset][:]\n",
    "    val_lb = labels[:offset]\n",
    "    \n",
    "    train_img = images[offset:][:]\n",
    "    train_lb = labels[offset:]\n",
    "    \n",
    "    return train_img, train_lb, val_img, val_lb    \n",
    "\n",
    "# 读取训练集和测试集数据\n",
    "[images, labels] = load_mnist('./MNIST', kind='train')\n",
    "[test_img, test_lb] = load_mnist('./MNIST',kind='test')\n",
    "train_img, train_lb, val_img, val_lb = data_split(images, labels, 1/6)\n",
    "\n",
    "\n",
    "# 打印查看数据集格式\n",
    "print('训练集图像格式为:', train_img.shape, '训练集标签格式为:', train_lb.shape)\n",
    "print('验证集图像格式为:', val_img.shape, '验证集标签格式为:', val_lb.shape)\n",
    "print('测试集图像格式为:', test_img.shape, '测试集标签格式为:', test_lb.shape)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "8acf03d4",
   "metadata": {},
   "source": [
    "## 用SGD+Momentum+CrossEntropyLoss来训练 Linear Classifier"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "b4b5a244",
   "metadata": {},
   "source": [
    "### 定义Cross Entropy Loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c6633e76",
   "metadata": {},
   "outputs": [],
   "source": [
    "def vectorized_loss_softmax(X, y, W):\n",
    "    \"\"\"\n",
    "    Inputs have dimension D=784, there are C=10 classes, and we operate on N=50000 examples.\n",
    "    \n",
    "    Inputs:\n",
    "    - W: Indexs of linear classifier, a numpy array of shape (D, C) containing weights.\n",
    "    - X: Training images, a numpy array of shape (N, D) containing a minibatch of data.\n",
    "    - y: Training labels, a numpy array of shape (N,) containing training labels; y[i] = c means\n",
    "         that X[i] has label c, where 0 <= c < C.\n",
    "    \n",
    "    Returns a tuple of:\n",
    "    - Softmax loss as single float.\n",
    "    \"\"\"\n",
    "    \n",
    "    # set the value of delta, lamda\n",
    "    delta = 1.0\n",
    "    lamda = 1.0\n",
    "    num_train = X.shape[0]\n",
    "    num_class = W.shape[1]\n",
    "    \n",
    "    # scores: class x examples\n",
    "    scores = W.T.dot(X.T).reshape(num_class, num_train)\n",
    "    \n",
    "    # scores_max: 1 x examples, get the max value from each column\n",
    "    scores_max = np.reshape(np.max(scores, axis=0), (1, num_train))\n",
    "\n",
    "    # prob: class x examples, calculate the log probability\n",
    "    # use scores_max to limit the boundary of exp indexes\n",
    "    prob = np.exp(scores-scores_max) / np.sum(np.exp(scores-scores_max), axis=0)\n",
    "\n",
    "    # set value 1 in true label positions, 0 for false labels\n",
    "    y_true = np.zeros(prob.shape)\n",
    "    y_true[y, np.arange(num_train)] = 1.0\n",
    "    \n",
    "    # calculate the average data loss\n",
    "    loss = -np.sum(y_true * np.log(prob))/num_train\n",
    "    \n",
    "    # add L1 regularization loss\n",
    "    rw = np.sum(np.abs(W))\n",
    "    loss += lamda * rw\n",
    "    \n",
    "    return loss"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "6c7551a0",
   "metadata": {},
   "source": [
    "### 定义梯度计算函数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "39e7e018",
   "metadata": {},
   "outputs": [],
   "source": [
    "# compute the numeric gradient\n",
    "def compute_gradient(img, lb, X):\n",
    "    \"\"\"\n",
    "    Inputs have dimension D=784, there are C=10 classes, and we operate on N=1000 examples.\n",
    "    \n",
    "    Inputs:\n",
    "    - img: Training images, a numpy array of shape (N, D) containing a minibatch of data.\n",
    "    - lb: Training labels, a numpy array of shape (N,) containing training labels; y[i] = c means\n",
    "          that X[i] has label c, where 0 <= c < C.\n",
    "    - X: Indexs of linear classifier, a numpy array of shape (D, C) containing weights.\n",
    "    \n",
    "    Returns:\n",
    "    - Numeric gradient dx\n",
    "    \"\"\"\n",
    "    \n",
    "    # initalize the gradient matrix dx\n",
    "    dx = np.zeros(X.shape)\n",
    "    h = 0.0001\n",
    "    \n",
    "    # calculate the inital loss fx\n",
    "    fx = vectorized_loss_softmax(img, lb, X)\n",
    "    \n",
    "    # iterate the each value\n",
    "    for c in range(X.shape[1]):\n",
    "        for d in range(X.shape[0]):\n",
    "            # evaluate function(x+h)\n",
    "            org_val = X[d][c]\n",
    "\n",
    "            # increment by h\n",
    "            X[d][c] = org_val + h\n",
    "\n",
    "            # evalute the softmax loss for f(x+h)\n",
    "            fxh = vectorized_loss_softmax(img, lb, X)\n",
    "\n",
    "            # restore to previous value\n",
    "            X[d][c] = org_val\n",
    "\n",
    "            # compute the partial derivative\n",
    "            dx[d][c] = (fxh - fx) / h\n",
    "\n",
    "    return dx\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "7a78692b",
   "metadata": {},
   "source": [
    "### 定义SGD+Momentum优化器"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "ec0932db",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# SGD training function\n",
    "def Train_with_SGD(img, lb, epoch):\n",
    "    \"\"\"\n",
    "    Inputs have dimension D=784, there are C=10 classes, and we operate on N=1000 examples.\n",
    "    \n",
    "    Inputs:\n",
    "    - img: Training images, a numpy array of shape (N, D) containing a minibatch of data.\n",
    "    - lb: Training labels, a numpy array of shape (N,) containing training labels; y[i] = c means\n",
    "          that X[i] has label c, where 0 <= c < C.\n",
    "    - epoch: Training iterations, an integer.\n",
    "    \n",
    "    Returns:\n",
    "    - Best indexs X\n",
    "    \"\"\"\n",
    "    \n",
    "    # set the hyperparameters\n",
    "    beta1 = 0.9\n",
    "    beta2 = 0.999\n",
    "    learning_rate = 5e-4\n",
    "    first_momentum = 0\n",
    "    second_momentum = 0\n",
    "    \n",
    "    # initialize the indexs X\n",
    "    X = np.random.randn(img.shape[1], 10) * 0.0001\n",
    "    \n",
    "    # start training\n",
    "    for i in range(1, epoch + 1):\n",
    "        # compute the gradient\n",
    "        dx = compute_gradient(img, lb,X)\n",
    "        \n",
    "        # momentum\n",
    "        first_momentum = beta1 * first_momentum + (1-beta1) * dx\n",
    "        \n",
    "        # update the indexs X\n",
    "        X -= learning_rate * first_momentum \n",
    "        \n",
    "        # calculate the loss and accuracy\n",
    "        loss = vectorized_loss_softmax(img,lb , X)\n",
    "        scores =  X.T.dot(img.T)\n",
    "        y_pred = np.argmax(scores, axis=0)\n",
    "        accuracy = np.mean(y_pred == lb) * 100\n",
    "        \n",
    "        # print the result\n",
    "        print(\"Epoch: %d  Loss: %.3f  Acc: %.3f%%\" % (i, loss, accuracy))\n",
    "    \n",
    "    return X"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "496a39e5",
   "metadata": {},
   "source": [
    "### 在训练集上进行训练"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "bab40dd9",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1  Loss: 4.299  Acc: 37.100%\n",
      "Epoch: 2  Loss: 11.181  Acc: 56.900%\n",
      "Epoch: 3  Loss: 19.426  Acc: 44.900%\n",
      "Epoch: 4  Loss: 21.622  Acc: 50.100%\n",
      "Epoch: 5  Loss: 20.153  Acc: 51.800%\n",
      "Epoch: 6  Loss: 16.962  Acc: 55.100%\n",
      "Epoch: 7  Loss: 13.161  Acc: 58.800%\n",
      "Epoch: 8  Loss: 13.997  Acc: 64.800%\n",
      "Epoch: 9  Loss: 19.096  Acc: 56.400%\n",
      "Epoch: 10  Loss: 16.267  Acc: 62.000%\n",
      "Epoch: 11  Loss: 13.772  Acc: 72.000%\n",
      "Epoch: 12  Loss: 12.681  Acc: 78.400%\n",
      "Epoch: 13  Loss: 13.104  Acc: 77.900%\n",
      "Epoch: 14  Loss: 13.260  Acc: 81.000%\n",
      "Epoch: 15  Loss: 13.676  Acc: 83.200%\n",
      "Epoch: 16  Loss: 14.031  Acc: 82.500%\n",
      "Epoch: 17  Loss: 13.649  Acc: 84.700%\n",
      "Epoch: 18  Loss: 13.132  Acc: 86.100%\n",
      "Epoch: 19  Loss: 12.738  Acc: 83.600%\n",
      "Epoch: 20  Loss: 11.863  Acc: 86.400%\n",
      "Epoch: 21  Loss: 10.851  Acc: 89.300%\n",
      "Epoch: 22  Loss: 10.419  Acc: 88.500%\n",
      "Epoch: 23  Loss: 10.243  Acc: 86.700%\n",
      "Epoch: 24  Loss: 9.999  Acc: 88.800%\n",
      "Epoch: 25  Loss: 9.906  Acc: 88.000%\n",
      "Epoch: 26  Loss: 9.695  Acc: 84.400%\n",
      "Epoch: 27  Loss: 8.908  Acc: 86.600%\n",
      "Epoch: 28  Loss: 8.031  Acc: 90.100%\n",
      "Epoch: 29  Loss: 7.568  Acc: 90.700%\n",
      "Epoch: 30  Loss: 7.514  Acc: 86.500%\n",
      "Epoch: 31  Loss: 7.264  Acc: 87.900%\n",
      "Epoch: 32  Loss: 6.827  Acc: 90.900%\n",
      "Epoch: 33  Loss: 6.583  Acc: 88.500%\n",
      "Epoch: 34  Loss: 6.257  Acc: 87.600%\n",
      "Epoch: 35  Loss: 5.646  Acc: 90.200%\n",
      "Epoch: 36  Loss: 5.378  Acc: 87.900%\n",
      "Epoch: 37  Loss: 5.204  Acc: 87.800%\n",
      "Epoch: 38  Loss: 5.351  Acc: 83.500%\n",
      "Epoch: 39  Loss: 5.019  Acc: 80.200%\n",
      "Epoch: 40  Loss: 5.093  Acc: 81.300%\n",
      "Epoch: 41  Loss: 4.474  Acc: 81.500%\n",
      "Epoch: 42  Loss: 4.967  Acc: 68.500%\n",
      "Epoch: 43  Loss: 7.088  Acc: 71.800%\n",
      "Epoch: 44  Loss: 10.441  Acc: 71.000%\n",
      "Epoch: 45  Loss: 9.993  Acc: 67.700%\n",
      "Epoch: 46  Loss: 6.123  Acc: 64.600%\n",
      "Epoch: 47  Loss: 11.069  Acc: 48.800%\n",
      "Epoch: 48  Loss: 10.727  Acc: 48.500%\n",
      "Epoch: 49  Loss: 10.621  Acc: 58.500%\n",
      "Epoch: 50  Loss: 10.555  Acc: 61.000%\n",
      "Epoch: 51  Loss: 11.444  Acc: 57.900%\n",
      "Epoch: 52  Loss: 7.335  Acc: 79.200%\n",
      "Epoch: 53  Loss: 8.400  Acc: 76.100%\n",
      "Epoch: 54  Loss: 9.652  Acc: 69.200%\n",
      "Epoch: 55  Loss: 9.122  Acc: 76.300%\n",
      "Epoch: 56  Loss: 7.932  Acc: 84.400%\n",
      "Epoch: 57  Loss: 8.429  Acc: 77.400%\n",
      "Epoch: 58  Loss: 7.953  Acc: 81.500%\n",
      "Epoch: 59  Loss: 7.562  Acc: 85.000%\n",
      "Epoch: 60  Loss: 8.138  Acc: 76.700%\n",
      "Epoch: 61  Loss: 6.898  Acc: 86.700%\n",
      "Epoch: 62  Loss: 6.972  Acc: 84.600%\n",
      "Epoch: 63  Loss: 6.665  Acc: 85.800%\n",
      "Epoch: 64  Loss: 6.343  Acc: 87.000%\n",
      "Epoch: 65  Loss: 6.392  Acc: 83.600%\n",
      "Epoch: 66  Loss: 5.629  Acc: 87.500%\n",
      "Epoch: 67  Loss: 5.230  Acc: 87.500%\n",
      "Epoch: 68  Loss: 5.308  Acc: 82.400%\n",
      "Epoch: 69  Loss: 4.623  Acc: 88.800%\n",
      "Epoch: 70  Loss: 4.669  Acc: 83.500%\n",
      "Epoch: 71  Loss: 4.445  Acc: 82.400%\n",
      "Epoch: 72  Loss: 4.446  Acc: 79.300%\n",
      "Epoch: 73  Loss: 4.291  Acc: 72.100%\n",
      "Epoch: 74  Loss: 5.770  Acc: 76.900%\n",
      "Epoch: 75  Loss: 6.092  Acc: 76.400%\n",
      "Epoch: 76  Loss: 4.644  Acc: 77.200%\n",
      "Epoch: 77  Loss: 5.475  Acc: 55.900%\n",
      "Epoch: 78  Loss: 4.299  Acc: 74.800%\n",
      "Epoch: 79  Loss: 4.390  Acc: 79.400%\n",
      "Epoch: 80  Loss: 4.955  Acc: 71.400%\n",
      "Epoch: 81  Loss: 5.274  Acc: 72.300%\n",
      "Epoch: 82  Loss: 6.640  Acc: 62.600%\n",
      "Epoch: 83  Loss: 6.807  Acc: 60.700%\n",
      "Epoch: 84  Loss: 5.525  Acc: 72.200%\n",
      "Epoch: 85  Loss: 7.350  Acc: 64.100%\n",
      "Epoch: 86  Loss: 7.730  Acc: 64.800%\n",
      "Epoch: 87  Loss: 5.975  Acc: 74.700%\n",
      "Epoch: 88  Loss: 7.255  Acc: 66.300%\n",
      "Epoch: 89  Loss: 7.426  Acc: 74.000%\n",
      "Epoch: 90  Loss: 8.520  Acc: 76.400%\n",
      "Epoch: 91  Loss: 7.491  Acc: 79.000%\n",
      "Epoch: 92  Loss: 5.901  Acc: 84.000%\n",
      "Epoch: 93  Loss: 8.030  Acc: 62.600%\n",
      "Epoch: 94  Loss: 5.687  Acc: 84.200%\n",
      "Epoch: 95  Loss: 6.174  Acc: 84.800%\n",
      "Epoch: 96  Loss: 6.501  Acc: 84.200%\n",
      "Epoch: 97  Loss: 5.677  Acc: 84.900%\n",
      "Epoch: 98  Loss: 5.334  Acc: 85.100%\n",
      "Epoch: 99  Loss: 5.243  Acc: 81.300%\n",
      "Epoch: 100  Loss: 4.759  Acc: 85.300%\n"
     ]
    }
   ],
   "source": [
    "# train the linear classifier with adam in 1000 examples\n",
    "epoch = 100\n",
    "best_X = Train_with_SGD(train_img[0:1000], train_lb[0:1000], epoch)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "3e11efc6",
   "metadata": {},
   "source": [
    "### 在验证集上测试分类效果"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "3cfb9030",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SGD_Momentum优化器在验证集上的分类精度为: 76.690%\n"
     ]
    }
   ],
   "source": [
    "# test the classification accuracy on validation dataset\n",
    "\n",
    "# scores: class x examples\n",
    "scores =  best_X.T.dot(val_img.T)\n",
    "\n",
    "# get the predicted labels\n",
    "# y_pred: examples\n",
    "y_pred = np.argmax(scores, axis=0)\n",
    "\n",
    "# calculate the accuracy\n",
    "accuracy = np.mean(y_pred == val_lb) * 100\n",
    "\n",
    "# print the accuracy\n",
    "print(\"SGD_Momentum优化器在验证集上的分类精度为: %.3f%%\" % accuracy)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "991023bb",
   "metadata": {},
   "source": [
    "## 使用Adam优化器进行训练"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "66a44e15",
   "metadata": {},
   "source": [
    "### 定义Adam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "acd0371c",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Adam training function\n",
    "def Train_with_Adam(img, lb, epoch):\n",
    "    \"\"\"\n",
    "    Inputs have dimension D=784, there are C=10 classes, and we operate on N=1000 examples.\n",
    "    \n",
    "    Inputs:\n",
    "    - img: Training images, a numpy array of shape (N, D) containing a minibatch of data.\n",
    "    - lb: Training labels, a numpy array of shape (N,) containing training labels; y[i] = c means\n",
    "          that X[i] has label c, where 0 <= c < C.\n",
    "    - epoch: Training iterations, an integer.\n",
    "    \n",
    "    Returns:\n",
    "    - Best indexs X\n",
    "    \"\"\"\n",
    "    \n",
    "    # set the hyperparameters\n",
    "    beta1 = 0.9\n",
    "    beta2 = 0.999\n",
    "    learning_rate = 5e-4\n",
    "    first_momentum = 0\n",
    "    second_momentum = 0\n",
    "    \n",
    "    # initialize the indexs X\n",
    "    X = np.random.randn(img.shape[1], 10) * 0.0001\n",
    "    \n",
    "    # start training\n",
    "    for i in range(1, epoch + 1):\n",
    "        # compute the gradient\n",
    "        dx = compute_gradient(img, lb, X)\n",
    "        \n",
    "        # momentum\n",
    "        first_momentum = beta1* first_momentum + (1-beta1)*dx\n",
    "        # adagrad\n",
    "        second_momentum = beta2*second_momentum +(1-beta2)*dx*dx\n",
    "        \n",
    "        # bias correction\n",
    "        first_unbias = first_momentum /(1-beta1**i)\n",
    "        second_unbias = second_momentum/(1-beta2**i)\n",
    "        \n",
    "        # update the indexs X\n",
    "        X -= learning_rate * first_unbias / (np.sqrt(second_unbias)+1e-7)\n",
    "        \n",
    "        # calculate the loss and accuracy\n",
    "        loss = vectorized_loss_softmax(img, lb, X)\n",
    "        scores =  X.T.dot(img.T)\n",
    "        y_pred = np.argmax(scores, axis=0)\n",
    "        accuracy = np.mean(y_pred == lb) * 100\n",
    "        \n",
    "        # print the result\n",
    "        print(\"Epoch: %d  Loss: %.3f  Acc: %.3f%%\" % (i, loss, accuracy))\n",
    "    \n",
    "    return X"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "bf551c4f",
   "metadata": {},
   "source": [
    "### 在训练集上进行训练"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ed6f7745",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1  Loss: 6.147  Acc: 41.900%\n",
      "Epoch: 2  Loss: 6.465  Acc: 61.600%\n",
      "Epoch: 3  Loss: 6.280  Acc: 67.100%\n",
      "Epoch: 4  Loss: 6.216  Acc: 68.700%\n",
      "Epoch: 5  Loss: 5.898  Acc: 72.500%\n",
      "Epoch: 6  Loss: 5.505  Acc: 72.800%\n",
      "Epoch: 7  Loss: 4.321  Acc: 80.600%\n",
      "Epoch: 8  Loss: 3.914  Acc: 87.100%\n",
      "Epoch: 9  Loss: 4.061  Acc: 86.000%\n",
      "Epoch: 10  Loss: 4.376  Acc: 76.800%\n",
      "Epoch: 11  Loss: 4.265  Acc: 75.600%\n",
      "Epoch: 12  Loss: 3.708  Acc: 82.800%\n",
      "Epoch: 13  Loss: 3.380  Acc: 89.100%\n",
      "Epoch: 14  Loss: 3.216  Acc: 89.200%\n",
      "Epoch: 15  Loss: 3.067  Acc: 87.100%\n",
      "Epoch: 16  Loss: 3.123  Acc: 85.600%\n",
      "Epoch: 17  Loss: 3.117  Acc: 85.800%\n",
      "Epoch: 18  Loss: 2.933  Acc: 86.000%\n",
      "Epoch: 19  Loss: 2.645  Acc: 87.500%\n",
      "Epoch: 20  Loss: 2.462  Acc: 90.500%\n",
      "Epoch: 21  Loss: 2.370  Acc: 90.500%\n",
      "Epoch: 22  Loss: 2.269  Acc: 90.500%\n",
      "Epoch: 23  Loss: 2.255  Acc: 88.400%\n",
      "Epoch: 24  Loss: 2.179  Acc: 88.000%\n",
      "Epoch: 25  Loss: 1.990  Acc: 90.700%\n",
      "Epoch: 26  Loss: 1.834  Acc: 92.300%\n",
      "Epoch: 27  Loss: 1.822  Acc: 89.500%\n",
      "Epoch: 28  Loss: 1.796  Acc: 89.200%\n",
      "Epoch: 29  Loss: 1.732  Acc: 90.600%\n",
      "Epoch: 30  Loss: 1.639  Acc: 92.700%\n",
      "Epoch: 31  Loss: 1.617  Acc: 92.200%\n",
      "Epoch: 32  Loss: 1.618  Acc: 89.300%\n",
      "Epoch: 33  Loss: 1.512  Acc: 93.700%\n",
      "Epoch: 34  Loss: 1.505  Acc: 91.000%\n",
      "Epoch: 35  Loss: 1.489  Acc: 91.700%\n",
      "Epoch: 36  Loss: 1.460  Acc: 91.700%\n",
      "Epoch: 37  Loss: 1.402  Acc: 93.900%\n",
      "Epoch: 38  Loss: 1.416  Acc: 92.600%\n",
      "Epoch: 39  Loss: 1.393  Acc: 93.100%\n",
      "Epoch: 40  Loss: 1.359  Acc: 92.700%\n",
      "Epoch: 41  Loss: 1.355  Acc: 92.000%\n",
      "Epoch: 42  Loss: 1.333  Acc: 92.400%\n",
      "Epoch: 43  Loss: 1.314  Acc: 93.300%\n",
      "Epoch: 44  Loss: 1.329  Acc: 92.600%\n",
      "Epoch: 45  Loss: 1.304  Acc: 92.500%\n",
      "Epoch: 46  Loss: 1.292  Acc: 92.800%\n",
      "Epoch: 47  Loss: 1.292  Acc: 92.300%\n",
      "Epoch: 48  Loss: 1.276  Acc: 93.100%\n",
      "Epoch: 49  Loss: 1.279  Acc: 92.600%\n",
      "Epoch: 50  Loss: 1.273  Acc: 92.400%\n",
      "Epoch: 51  Loss: 1.257  Acc: 92.500%\n",
      "Epoch: 52  Loss: 1.254  Acc: 91.900%\n",
      "Epoch: 53  Loss: 1.252  Acc: 92.700%\n",
      "Epoch: 54  Loss: 1.246  Acc: 93.200%\n",
      "Epoch: 55  Loss: 1.239  Acc: 92.400%\n",
      "Epoch: 56  Loss: 1.226  Acc: 92.200%\n",
      "Epoch: 57  Loss: 1.223  Acc: 92.500%\n",
      "Epoch: 58  Loss: 1.224  Acc: 92.600%\n",
      "Epoch: 59  Loss: 1.225  Acc: 93.000%\n",
      "Epoch: 60  Loss: 1.221  Acc: 92.400%\n",
      "Epoch: 61  Loss: 1.214  Acc: 92.500%\n",
      "Epoch: 62  Loss: 1.213  Acc: 93.300%\n",
      "Epoch: 63  Loss: 1.211  Acc: 93.000%\n",
      "Epoch: 64  Loss: 1.209  Acc: 92.700%\n",
      "Epoch: 65  Loss: 1.209  Acc: 93.100%\n",
      "Epoch: 66  Loss: 1.204  Acc: 93.100%\n",
      "Epoch: 67  Loss: 1.206  Acc: 92.800%\n",
      "Epoch: 68  Loss: 1.208  Acc: 93.500%\n",
      "Epoch: 69  Loss: 1.205  Acc: 93.000%\n",
      "Epoch: 70  Loss: 1.203  Acc: 92.700%\n",
      "Epoch: 71  Loss: 1.201  Acc: 93.300%\n",
      "Epoch: 72  Loss: 1.200  Acc: 93.200%\n",
      "Epoch: 73  Loss: 1.201  Acc: 93.400%\n",
      "Epoch: 74  Loss: 1.199  Acc: 92.900%\n",
      "Epoch: 75  Loss: 1.195  Acc: 93.100%\n",
      "Epoch: 76  Loss: 1.198  Acc: 93.300%\n",
      "Epoch: 77  Loss: 1.198  Acc: 93.100%\n",
      "Epoch: 78  Loss: 1.197  Acc: 93.400%\n",
      "Epoch: 79  Loss: 1.195  Acc: 93.300%\n",
      "Epoch: 80  Loss: 1.193  Acc: 93.300%\n",
      "Epoch: 81  Loss: 1.196  Acc: 93.300%\n",
      "Epoch: 82  Loss: 1.196  Acc: 93.000%\n",
      "Epoch: 83  Loss: 1.196  Acc: 93.200%\n",
      "Epoch: 84  Loss: 1.194  Acc: 93.300%\n",
      "Epoch: 85  Loss: 1.194  Acc: 93.200%\n",
      "Epoch: 86  Loss: 1.195  Acc: 93.100%\n",
      "Epoch: 87  Loss: 1.195  Acc: 93.100%\n",
      "Epoch: 88  Loss: 1.195  Acc: 93.400%\n",
      "Epoch: 89  Loss: 1.202  Acc: 92.700%\n",
      "Epoch: 90  Loss: 1.211  Acc: 92.700%\n",
      "Epoch: 91  Loss: 1.245  Acc: 91.600%\n",
      "Epoch: 92  Loss: 1.257  Acc: 91.500%\n",
      "Epoch: 93  Loss: 1.241  Acc: 90.700%\n",
      "Epoch: 94  Loss: 1.204  Acc: 93.100%\n",
      "Epoch: 95  Loss: 1.211  Acc: 93.600%\n",
      "Epoch: 96  Loss: 1.241  Acc: 91.200%\n",
      "Epoch: 97  Loss: 1.228  Acc: 92.300%\n",
      "Epoch: 98  Loss: 1.197  Acc: 93.300%\n",
      "Epoch: 99  Loss: 1.229  Acc: 92.000%\n",
      "Epoch: 100  Loss: 1.242  Acc: 91.600%\n"
     ]
    }
   ],
   "source": [
    "# train the linear classifier with adam in 1000 examples\n",
    "epoch = 100\n",
    "best_X = Train_with_Adam(train_img[0:1000], train_lb[0:1000], epoch)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "3dd745f7",
   "metadata": {},
   "source": [
    "### 在验证集上测试分类效果"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "3de76cdc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SGD_Momentum优化器在验证集上的分类精度为: 81.870%\n"
     ]
    }
   ],
   "source": [
    "# test the classification accuracy on validation dataset\n",
    "\n",
    "# scores: class x examples\n",
    "scores =  best_X.T.dot(val_img.T)\n",
    "\n",
    "# get the predicted labels\n",
    "# y_pred: examples\n",
    "y_pred = np.argmax(scores, axis=0)\n",
    "\n",
    "# calculate the accuracy\n",
    "accuracy = np.mean(y_pred == val_lb) * 100\n",
    "\n",
    "# print the accuracy\n",
    "print(\"SGD_Momentum优化器在验证集上的分类精度为: %.3f%%\" % accuracy)"
   ]
  },
  {
   "cell_type": "raw",
   "id": "3682d87f-5dc6-403e-be37-51720b649845",
   "metadata": {},
   "source": [
    "两种方法均可以求得较小的loss\n",
    "\n",
    "\n",
    "SGD:\n",
    "Epoch: 100  Loss: 4.759  Acc: 85.300%\n",
    "SGD_Momentum优化器在验证集上的分类精度为: 76.690%\n",
    "\n",
    "\n",
    "Adam:\n",
    "Epoch: 100  Loss: 1.242  Acc: 91.600%\n",
    "Adam优化器在验证集上的分类精度为: 81.870%\n",
    "\n",
    "\n",
    "\n",
    "adam的loss取得的更低的值而且精确度更高\n",
    "\n",
    "个人认为有以下几种可能：\n",
    "1loss的计算中没有加入正则化项，有可能出现过拟合\n",
    "2单个层的线性分类器无法解决这个问题\n",
    "\n",
    "同时存在一些问题\n",
    "1计算梯度时的时间复杂度太高\n",
    "可以采用反向梯度传播进行梯度计算\n",
    "\n",
    "2loss这里使用的是均方误差，可以更换为交叉熵损失"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
