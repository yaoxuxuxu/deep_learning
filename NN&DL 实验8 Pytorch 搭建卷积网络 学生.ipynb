{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 读取数据"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "训练集图像格式为: (10000, 1, 28, 28) 训练集标签格式为: (10000,) 热编码训练集标签格式为: (10000, 10)\n",
      "验证集图像格式为: (10000, 1, 28, 28) 验证集标签格式为: (10000,) 热编码验证集标签格式为: (10000, 10)\n",
      "测试集图像格式为: (10000, 1, 28, 28) 测试集标签格式为: (10000,) 热编码测试集标签格式为: (10000, 10)\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import datasets\n",
    "from torchvision.transforms import ToTensor\n",
    "import gzip\n",
    "import os\n",
    "import struct\n",
    "import numpy as np\n",
    "\n",
    "def load_mnist(path, kind='train'):\n",
    "    \"\"\"加载MNIST数据集\"\"\"\n",
    "    labels_path = os.path.join(path, f'{kind}-labels-idx1-ubyte.gz')\n",
    "    images_path = os.path.join(path, f'{kind}-images-idx3-ubyte.gz')\n",
    "\n",
    "    with gzip.open(labels_path, 'rb') as lbpath:\n",
    "        struct.unpack('>II', lbpath.read(8))\n",
    "        labels = np.frombuffer(lbpath.read(), dtype=np.uint8)\n",
    "\n",
    "    with gzip.open(images_path, 'rb') as imgpath:\n",
    "        struct.unpack('>IIII', imgpath.read(16))\n",
    "        images = np.frombuffer(imgpath.read(), dtype=np.uint8).reshape(len(labels),1,28,28)\n",
    "\n",
    "    return images, labels\n",
    "\n",
    "\n",
    "\n",
    "# 数据集划分\n",
    "def data_split(images, labels, ratio):\n",
    "    \n",
    "    total_len = images.shape[0]\n",
    "    offset = int(total_len * ratio)\n",
    "\n",
    "    val_img = images[:offset][:]\n",
    "    val_lb = labels[:offset]\n",
    "\n",
    "    train_img = images[offset:][:]\n",
    "    train_lb = labels[offset:]\n",
    "\n",
    "    return train_img, train_lb, val_img, val_lb    \n",
    "\n",
    "# 读取训练集和测试集数据\n",
    "[images, labels] = load_mnist('./MNIST', kind='train')\n",
    "[test_img, test_lb] = load_mnist('./MNIST',kind='test')\n",
    "train_img, train_lb, val_img, val_lb = data_split(images, labels, 1/6)\n",
    "\n",
    "# 为了加快调试速度，从训练集选择2000个样本。\n",
    "random_numbers = np.random.randint(50000, size=(10000, ))\n",
    "train_img=train_img[random_numbers]\n",
    "train_lb= train_lb[random_numbers]\n",
    "\n",
    "# 将所有数据归一化到0-1之间\n",
    "train_img =train_img/255.\n",
    "val_img   =val_img/255.\n",
    "test_img  =test_img/255.\n",
    "\n",
    "# 对标签进行热编码\n",
    "one_hot_train_lb = np.eye(10)[train_lb]\n",
    "one_hot_val_lb = np.eye(10)[val_lb]\n",
    "one_hot_test_lb= np.eye(10)[test_lb]\n",
    "\n",
    "# 打印查看数据集格式\n",
    "print('训练集图像格式为:', train_img.shape, '训练集标签格式为:', train_lb.shape,'热编码训练集标签格式为:', one_hot_train_lb.shape)\n",
    "print('验证集图像格式为:', val_img.shape, '验证集标签格式为:', val_lb.shape,'热编码验证集标签格式为:', one_hot_val_lb.shape)\n",
    "print('测试集图像格式为:', test_img.shape, '测试集标签格式为:', test_lb.shape,'热编码测试集标签格式为:', one_hot_test_lb.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 数据增强处理"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([20000, 1, 28, 28])\n"
     ]
    }
   ],
   "source": [
    "\n",
    "from torchvision.transforms import v2\n",
    "from torchvision.io import read_image\n",
    "train_img1=torch.tensor(train_img, dtype=torch.float32)\n",
    "\n",
    "transforms = v2.Compose([\n",
    "    v2.RandomHorizontalFlip(p=0.5),\n",
    "    v2.Normalize(mean=[0.485], std=[0.229]),\n",
    "    v2.RandomRotation(degrees=(-45, 45))\n",
    "    ])\n",
    "\n",
    "augmented_sample = transforms(train_img1)\n",
    "train_img = torch.cat((augmented_sample,train_img1))\n",
    "one_hot_train_lb  = np.concatenate((one_hot_train_lb,one_hot_train_lb),axis=0)\n",
    "print(train_img.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.savez(\"dataset\",train_img,one_hot_train_lb,test_img,one_hot_train_lb)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "程序改错，构建并训练一个卷积网络"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_41384/1585435722.py:68: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  X=torch.tensor(X, dtype=torch.float32)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Epoch:1, loss: 2.014015,  Accuracy: 40.6%\n",
      " Epoch:2, loss: 1.265292,  Accuracy: 68.5%\n",
      " Epoch:3, loss: 0.731226,  Accuracy: 82.1%\n",
      " Epoch:4, loss: 0.468146,  Accuracy: 89.2%\n",
      " Epoch:5, loss: 0.343721,  Accuracy: 91.8%\n",
      " Epoch:6, loss: 0.274751,  Accuracy: 93.3%\n",
      " Epoch:7, loss: 0.231780,  Accuracy: 94.2%\n",
      " Epoch:8, loss: 0.202473,  Accuracy: 94.7%\n",
      " Epoch:9, loss: 0.181034,  Accuracy: 95.3%\n",
      " Epoch:10, loss: 0.164643,  Accuracy: 95.6%\n"
     ]
    }
   ],
   "source": [
    "#网络包含3个卷积层、2个线性层、3个BN层\n",
    "class NeuralNetwork(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.conv1=nn.Conv2d(in_channels=1,out_channels=10, kernel_size=5)\n",
    "        self.conv2=nn.Conv2d(in_channels=10,out_channels=20,kernel_size=5)\n",
    "        self.conv3=nn.Conv2d(in_channels=20,out_channels=10,kernel_size=5)\n",
    "        self.w1 =nn.Linear(16*16*10,100)\n",
    "        self.w2 =nn.Linear(100,10)\n",
    "        self.BN1=nn.BatchNorm2d(10)\n",
    "        self.BN2=nn.BatchNorm2d(20)\n",
    "        self.BN3=nn.BatchNorm2d(10)\n",
    "        self.relu=nn.ReLU()\n",
    "        #self.drop=nn.Dropout()\n",
    "\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.conv1 (x)\n",
    "        x = self.BN1(x)\n",
    "        x = self.relu(x)\n",
    "        #x= self.drop(x)\n",
    "        \n",
    "        x = self.conv2 (x)\n",
    "        x = self.BN2(x)\n",
    "        x = self.relu(x)\n",
    "\n",
    "        #x=self.drop(x)\n",
    "        \n",
    "        x = self.conv3 (x)\n",
    "        x = self.BN3(x)\n",
    "        x = self.relu(x)\n",
    "        #x=self.drop(x)\n",
    "        \n",
    "        x = x.view(x.size(0), -1)\n",
    "        x = self.w1 (x)\n",
    "        x = self.relu(x)\n",
    "\n",
    "        #x=self.drop(x)\n",
    "        \n",
    "        x = self.w2 (x)\n",
    "        x = self.relu(x)        \n",
    "        #x=self.drop(x)\n",
    "        return x\n",
    "\n",
    "model = NeuralNetwork()\n",
    "\n",
    "# Initialize the loss function\n",
    "loss_fn = nn.CrossEntropyLoss()\n",
    "\n",
    "learning_rate = 5e-3\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=learning_rate)\n",
    "\n",
    "batch_size = 200\n",
    "epochs = 10\n",
    "batch_num=int(train_img.shape[0]/batch_size)\n",
    "size = len(train_img)\n",
    "\n",
    "model.train()\n",
    "for t in range(epochs):\n",
    "    \n",
    "    correct=0.\n",
    "    train_mean_loss=0.\n",
    "\n",
    "    for batch in range(batch_num):\n",
    "        X=train_img[batch*batch_size:(batch+1)*batch_size,]\n",
    "        y=one_hot_train_lb[batch*batch_size:(batch+1)*batch_size,:]\n",
    "\n",
    "        X=torch.tensor(X, dtype=torch.float32)\n",
    "        y=torch.tensor(y, dtype=torch.float32)\n",
    "        \n",
    "        # Compute prediction and loss\n",
    "        pred = model(X)\n",
    "        loss = loss_fn(pred, y)\n",
    "\n",
    "        # Backpropagation\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        correct += (pred.argmax(1) == y.argmax(1)).type(torch.float).mean().item()\n",
    "        train_mean_loss+= loss.item()\n",
    "\n",
    "    train_mean_loss /= batch_num\n",
    "    correct /= batch_num\n",
    "    \n",
    "    print(f\" Epoch:{t+1}, loss: {train_mean_loss:>8f},  Accuracy: {(100*correct):>0.1f}%\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy: 96.2%, Test Avg loss: 0.145072 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "model.eval()\n",
    "test_loss, correct = 0, 0\n",
    "with torch.no_grad():\n",
    "        X=torch.tensor(test_img, dtype=torch.float32)\n",
    "        y=torch.tensor(one_hot_test_lb, dtype=torch.float32)\n",
    "        pred = model(X)\n",
    "        test_loss = np.mean(loss_fn(pred, y).item())\n",
    "        correct = (pred.argmax(1) == y.argmax(1)).type(torch.float).mean().item()\n",
    "\n",
    "print(f\"Test Accuracy: {(100*correct):>0.1f}%, Test Avg loss: {test_loss:>8f} \\n\")\n"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Epoch:10, loss: 0.164643,  Accuracy: 95.6%\n",
    "Test Accuracy: 96.2%, Test Avg loss: 0.145072 \n",
    "通过卷积层实现网络和全连接层相比而言\n",
    "参数量下降了，占用内存减少\n",
    "能够提取到结构上的一些东西，而全连接层不行\n",
    "但是二位卷积操作从算法速度而言，比全连接层的训练速度要慢不少\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
